{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fA-1bGi1pgXK",
        "Cet5xrc-YW10",
        "lCDVbH7IqMZK",
        "zNTwXSIgd-hQ",
        "f6nU_ptamwxS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Suggested Algorithm:\n",
        "1) Choosing part of the data (sentences up to 20 words)\n",
        "\n",
        "2) Perform word embedding using glove\n",
        "\n",
        "3) Cluster all the words using dbscan\n",
        "\n",
        "4) Change all words in the Dict to a \"Centroid\" \n",
        "\n",
        "5) Check if we get K=2 anonymity if not repeat  2-5\n",
        "\n",
        "6) If not yet - remove words that reduces k (put in parantesis)"
      ],
      "metadata": {
        "id": "I9Ti_dzxC-Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from numpy.linalg import norm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import islice\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "metadata": {
        "id": "ShTKnGBKDI8q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Choosing part of the data (sentences up to 20 words)\n"
      ],
      "metadata": {
        "id": "bdDZTHYrG1HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading the data\n",
        "COLAB = True\n",
        "first_run = True"
      ],
      "metadata": {
        "id": "S_C7Rov6G14h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    from os.path import exists\n",
        "\n",
        "    amazon_train_file = 'train.ft.txt.bz2'\n",
        "\n",
        "    if exists(amazon_train_file):\n",
        "        train_file = amazon_train_file\n",
        "    else:\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "        # For Hadas' drive\n",
        "        my_dir = 'drive/MyDrive/Y-data/Intuit-K-anonimity/'\n",
        "\n",
        "        # For Lior's drive\n",
        "        #my_dir = 'drive/MyDrive/Y-data/Y-DATA_PROJECT/'\n",
        "\n",
        "        train_file = my_dir + '/train.ft.txt.bz2'\n",
        "else:\n",
        "    train_file = '../data/' + 'train.ft.txt.bz2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd_4xukvJ0Jh",
        "outputId": "b6229f86-4a96-415f-f931-674864a1639e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit https://www.kaggle.com/code/anshulrai/cudnnlstm-implementation-93-7-accuracy\n",
        "\n",
        "import bz2\n",
        "\n",
        "# Readling the file to list of comments\n",
        "train_file = bz2.BZ2File(train_file)\n",
        "train_file_lines = train_file.readlines()\n",
        "\n",
        "# Converting from raw binary strings to strings that can be parsed\n",
        "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
        "\n",
        "# Extracting the labels and sentences\n",
        "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\n",
        "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines] # And converting to lower case"
      ],
      "metadata": {
        "id": "Cr1IAK-xJ0u9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(train_file_lines)  # Free RAM"
      ],
      "metadata": {
        "id": "iEUpyJgJA9AE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a data frame from train data:\n",
        "df = pd.DataFrame(list(zip(train_sentences, train_labels)), columns =['txt', 'sentiment'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sLORKsgEOpL4",
        "outputId": "a825c082-01c8-4743-98c8-4c48a711bd50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 txt  sentiment\n",
              "0  stuning even for the non-gamer: this sound tra...          1\n",
              "1  the best soundtrack ever to anything.: i'm rea...          1\n",
              "2  amazing!: this soundtrack is my favorite music...          1\n",
              "3  excellent soundtrack: i truly like this soundt...          1\n",
              "4  remember, pull your jaw off the floor after he...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b118edc-8d58-44f5-8c4a-749d55946418\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stuning even for the non-gamer: this sound tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the best soundtrack ever to anything.: i'm rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazing!: this soundtrack is my favorite music...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>excellent soundtrack: i truly like this soundt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>remember, pull your jaw off the floor after he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b118edc-8d58-44f5-8c4a-749d55946418')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b118edc-8d58-44f5-8c4a-749d55946418 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b118edc-8d58-44f5-8c4a-749d55946418');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the number of words"
      ],
      "metadata": {
        "id": "WlGKHkNcBJQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['num_of_words'] = df['txt'].apply(lambda x : len(x.split(' ')))"
      ],
      "metadata": {
        "id": "t_t55JxUBL_H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering only short sentences"
      ],
      "metadata": {
        "id": "ajzcfbq4BVZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "df_short_sentences = df[df['num_of_words'] <= max_len] # Filtering using pandas is much faster\n",
        "#short_train_sentences_total = [x for x in train_sentences if len(x.split(' ')) <= max_len]  # Much slower\n",
        "print(df_short_sentences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WyYf7sFBUNf",
        "outputId": "53bbe8ce-f32d-4f28-b1df-0842db363373"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43870, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To further filter the num of sentences we work on, and make our life easier for POC, we will use the Jaccard index and choose the sentences with highest score:"
      ],
      "metadata": {
        "id": "zI7JzlL-vkpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_index(sentence1, sentence2):\n",
        "    \"\"\" Calc Jaccard index for each pair of sentences \"\"\"\n",
        "    words1 = set(sentence1.split())\n",
        "    words2 = set(sentence2.split())\n",
        "    intersection = len(words1.intersection(words2))\n",
        "    union = len(words1.union(words2))\n",
        "    jaccard = intersection / union\n",
        "    return jaccard"
      ],
      "metadata": {
        "id": "2uvup_9MwzFx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard_index('I love white choclate', 'I love love brown choclate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSPY_muve33o",
        "outputId": "b32d6192-c6ab-4f14-817e-f9d77a34dc33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a list of index for df_short_sentences, to keep indces from original df:\n",
        "indices_list = list(df_short_sentences.index)\n",
        "# init Jaccard dict:\n",
        "jaccard_index_dict = {}"
      ],
      "metadata": {
        "id": "5zcdzd63w7TV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_list_short = indices_list[1:1000] # take only 1000 "
      ],
      "metadata": {
        "id": "RBnrbafwD7TX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TOO SLOW DONOT RUN THIS###\n",
        "# loop on index of sentences in the df:\n",
        "'''\n",
        "for sentence1_ind in indices_list:\n",
        "  sent_1 = df_short_sentences.txt.loc[sentence1_ind]\n",
        "  for sentence2_ind in indices_list[:-1]:\n",
        "      sent_2 = df_short_sentences.txt.loc[sentence2_ind]\n",
        "      jaccard_index_dict[sentence1_ind, sentence2_ind] = jaccard_index(sent_1, sent_2)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "_E4S5sFi3-DR",
        "outputId": "60a270a7-756b-4063-cd0c-5a1baf9818de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor sentence1_ind in indices_list:\\n  sent_1 = df_short_sentences.txt.loc[sentence1_ind]\\n  for sentence2_ind in indices_list[:-1]:\\n      sent_2 = df_short_sentences.txt.loc[sentence2_ind]\\n      jaccard_index_dict[sentence1_ind, sentence2_ind] = jaccard_index(sent_1, sent_2)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Create a list of sentence texts\n",
        "sentences = list(df_short_sentences.txt.loc[indices_list_short])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFTJ5jBJ9P9J",
        "outputId": "f420094d-4469-44bc-ef13-c1313005e93f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.24 ms, sys: 1.98 ms, total: 4.22 ms\n",
            "Wall time: 8.1 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Jaccard index for all pairs of sentences\n",
        "## more efficient code using ChatGPT:\n",
        "%%time\n",
        "jaccard_index_dict = {(indices_list_short[i],indices_list_short[j]): jaccard_index(sentences[i], sentences[j]) for i in range(len(sentences)) for j in range(i+1, len(sentences))}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnvBF_6HDm_o",
        "outputId": "230a9236-8e6d-444a-d023-5c34615832cb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.73 s, sys: 40.8 ms, total: 3.77 s\n",
            "Wall time: 3.81 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the dictionary by its values in descending order\n",
        "sorted_dict = dict(sorted(jaccard_index_dict.items(), key=lambda item: item[1], reverse=True))"
      ],
      "metadata": {
        "id": "3S6q47AzzTs7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first_50_items = dict(islice(sorted_dict.items(), 50)) # work with 50 sentences as a start\n",
        "# Hadas: Changed to 500 (no stopwords)\n",
        "first_50_items = dict(islice(sorted_dict.items(), 500)) # work with 50 sentences as a start"
      ],
      "metadata": {
        "id": "O1zlqSI2EoLu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the two sentences with highest JAccard ~0.8"
      ],
      "metadata": {
        "id": "PbqL2wheSujF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_short_sentences.loc[23472,\"txt\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "L0MeuzrwObxq",
        "outputId": "ae12d4a7-d893-434f-e3fb-022528758b18"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'poor quality: the seat covers started coming loose at the seams immediately upon putting them on the seats.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_short_sentences.loc[23473,\"txt\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Xy1ZEkvcSss3",
        "outputId": "ee140a4c-8e75-4609-b950-cef7d7853982"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'poor quality.: the seat covers started coming loose at the seams immediately upon putting them on the seats.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a list of all index:\n",
        "unique_numbers = [num for tup in first_50_items.keys() for num in tup]  # list of indeces for sentences to work with"
      ],
      "metadata": {
        "id": "cLUy3M090b5W"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter the df to get the 50 chosen sentences\n"
      ],
      "metadata": {
        "id": "a4lLvuzU2pHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter the df to recive only these sentences and print df\n",
        "filtered_df = df_short_sentences.loc[df_short_sentences.index.isin(unique_numbers)]\n",
        "print(filtered_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvu_9j-u2k7w",
        "outputId": "ca33bb02-ae58-4ab3-ec1a-13af26873335"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    txt  sentiment  \\\n",
            "446   good value: i love curve and this is a large b...          1   \n",
            "669   janes all the worlds aircraft 1996-7: great to...          1   \n",
            "1806  ninnia: this monitor is great. the service i g...          1   \n",
            "1811  most informative: this is the most informative...          1   \n",
            "2396  like the critics say: riveting!: the book was ...          1   \n",
            "\n",
            "      num_of_words  \n",
            "446             20  \n",
            "669             18  \n",
            "1806            20  \n",
            "1811            20  \n",
            "2396            18  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Working with a copy of the df:\n",
        "filtered_df_copy = filtered_df.copy()"
      ],
      "metadata": {
        "id": "wStkA6ppgi92"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Perform word embedding using glove"
      ],
      "metadata": {
        "id": "ytXUKrLbKLuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1) Load the model:\n"
      ],
      "metadata": {
        "id": "NU1ZQeUWKMNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "glove_model = api.load('glove-twitter-25')"
      ],
      "metadata": {
        "id": "JZAUDGT9N4x9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ad01ca-9f50-45a1-84d8-9ecc8e6fbb7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TRYING TO COMBINE TO A FUNCTION"
      ],
      "metadata": {
        "id": "Kz6bf5K3movS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SKIP LINE\n",
        "#https://blog.paperspace.com/pre-trained-word-embeddings-natural-language-processing/\n",
        "X = filtered_df_copy['txt']\n",
        "y = filtered_df_copy['sentiment']"
      ],
      "metadata": {
        "id": "EXlCE1mqN5AH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "vocab_size = 10000\n",
        "oov_token = \"<OOV>\"  # words OOV\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "metadata": {
        "id": "UbJh9nQ2N5We"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping of the words to numbers\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "o1xxoyiAN5ZK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing stopwords before embedding embedding"
      ],
      "metadata": {
        "id": "JPeAz8bTnzAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "sw = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOgCzGein4Lp",
        "outputId": "e12f02fb-b6e5-4df8-d3f9-c5a0cda940ce"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using CHATGPT\n",
        "# Iterate over your dictionary of words and embed them using GloVe\n",
        "embedded_dict = {}\n",
        "for word, idx in word_index.items():\n",
        "    if word not in sw:\n",
        "        try:\n",
        "            embedded_dict[word] = glove_model[word]\n",
        "        except KeyError:\n",
        "            # If the word is not in the GloVe vocabulary, assign a default embedding or skip it\n",
        "            pass"
      ],
      "metadata": {
        "id": "r6u2XzM8m8C-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the embeddings for the first 5 words in your dictionary\n",
        "print(list(embedded_dict.items())[:5])\n",
        "#print( next(iter((embedded_dict.items())) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75_zJwFDm8FP",
        "outputId": "51bef827-6984-4f59-9862-235110729e39"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('great', array([-8.4229e-01,  3.6512e-01, -3.8841e-01, -4.6118e-01,  2.4301e-01,\n",
            "        3.2412e-01,  1.9009e+00, -2.2630e-01, -3.1335e-01, -1.0970e+00,\n",
            "       -4.1494e-03,  6.2074e-01, -5.0964e+00,  6.7418e-01,  5.0080e-01,\n",
            "       -6.2119e-01,  5.1765e-01, -4.4122e-01, -1.4364e-01,  1.9130e-01,\n",
            "       -7.4608e-01, -2.5903e-01, -7.8010e-01,  1.1030e-01, -2.7928e-01],\n",
            "      dtype=float32)), ('book', array([ 0.21621 ,  0.056781,  0.82955 , -0.1424  ,  0.82832 , -0.87341 ,\n",
            "        1.699   , -0.25702 ,  0.65303 , -0.82435 ,  0.26496 ,  0.4612  ,\n",
            "       -4.0463  , -0.044556,  0.15648 , -0.083655,  0.72399 ,  0.20802 ,\n",
            "       -0.27561 , -0.024987, -0.83992 , -0.92536 , -0.95454 ,  0.42348 ,\n",
            "       -0.14709 ], dtype=float32)), ('movie', array([ 0.3569  , -0.24292 ,  1.5525  , -0.40293 ,  0.053246, -0.38882 ,\n",
            "        2.1696  ,  0.54185 ,  0.12384 , -0.88946 , -0.18272 ,  0.64263 ,\n",
            "       -3.8322  ,  0.12828 ,  0.38866 ,  0.9754  ,  0.56106 , -0.048216,\n",
            "       -0.47214 ,  0.58174 , -0.67981 ,  0.26981 , -0.50217 , -0.41104 ,\n",
            "        0.59677 ], dtype=float32)), ('good', array([-0.54403 ,  0.60274 , -0.14543 , -0.023398, -0.13771 ,  0.60137 ,\n",
            "        2.192   ,  0.20804 , -0.51536 , -0.23101 , -0.80387 ,  0.56901 ,\n",
            "       -5.0234  ,  0.26507 ,  0.47891 , -0.59854 ,  0.56132 , -1.0905  ,\n",
            "       -0.52587 ,  0.12506 , -0.22624 ,  0.24529 , -0.45767 ,  0.92619 ,\n",
            "        0.022125], dtype=float32)), ('condition', array([-0.86033  , -0.66328  , -1.3903   ,  0.51634  ,  0.8573   ,\n",
            "        0.24926  ,  0.47284  , -0.78624  ,  0.46349  ,  0.27668  ,\n",
            "        0.39554  ,  0.60445  , -2.6948   ,  0.98464  ,  0.80247  ,\n",
            "        0.38314  ,  0.41455  ,  0.72861  ,  0.32357  , -0.4001   ,\n",
            "        0.47402  , -0.26614  ,  0.23206  ,  0.0057436, -0.9839   ],\n",
            "      dtype=float32))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### using ChatGPT for the following clustering steps:"
      ],
      "metadata": {
        "id": "OzbygH5Pm8H4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Cluster all the words using dbscan\n",
        "\n",
        "*Import* the necessary libraries:\n"
      ],
      "metadata": {
        "id": "fA-1bGi1pgXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "38Q1NWE7pi-C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the embeddings from the embedded_dict and store them in a numpy array:"
      ],
      "metadata": {
        "id": "7gDDX7tUpnby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.array(list(embedded_dict.values()))\n"
      ],
      "metadata": {
        "id": "xnDjo9NZpjAr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the best epsilon using the elbow method"
      ],
      "metadata": {
        "id": "eYVP_oosYeOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"k-distance graph\", and the elbow point in the graph can be used to estimate a reasonable value of eps. The elbow point is the point where the curve changes from steep to shallow."
      ],
      "metadata": {
        "id": "MxGRoHDQrC5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade kneed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBIYztH3PZk6",
        "outputId": "ba5780ee-abb4-48bd-d9e2-f2bf648776be"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kneed\n",
            "  Downloading kneed-0.8.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from kneed) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.9/dist-packages (from kneed) (1.22.4)\n",
            "Installing collected packages: kneed\n",
            "Successfully installed kneed-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CODE USED TO FINED EPS VALUE == NO NEED TO RUN THIS AGAIN\n",
        "if True: \n",
        "    from kneed import KneeLocator\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "    # Compute the k-distances for each point\n",
        "    k = 10\n",
        "    neigh = NearestNeighbors(n_neighbors=k)\n",
        "    neigh.fit(embeddings)\n",
        "    distances, indices = neigh.kneighbors(embeddings)\n",
        "\n",
        "    # Sort the distances and flatten them into a 1D array\n",
        "    sorted_distances = np.sort(distances[:,k-1], axis=None)\n",
        "\n",
        "    # Plot the k-distance graph\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(sorted_distances)\n",
        "\n",
        "    # Find the elbow point\n",
        "    kneedle = KneeLocator(range(len(sorted_distances)), sorted_distances, S=1.0, curve='concave', direction='increasing')\n",
        "    eps = sorted_distances[kneedle.elbow]\n",
        "\n",
        "    print(f\"Estimated eps value: {eps}\")\n",
        "\n",
        "    first_run=False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EW7LsLXPrCVl",
        "outputId": "d2d74d24-e3e8-4f2a-f005-1674e31d7549"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated eps value: 1.8913299885517314\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the DBSCAN object with the desired parameters:\n"
      ],
      "metadata": {
        "id": "7MINx0wAppRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dbscan = DBSCAN(eps=2.1, min_samples=3)  # <0.5 returned only one cluster. Chose 3 a min words per cluster (maybe reduce to 2?)\n",
        "#dbscan = DBSCAN(eps=1.95, min_samples=2)  # <0.5 returned only one cluster. Chose 3 a min words per cluster (maybe reduce to 2?) Maybe according to k\n",
        "dbscan = DBSCAN(eps=eps, min_samples=2)  # <0.5 returned only one cluster. Chose 3 a min words per cluster (maybe reduce to 2?) Maybe according to k"
      ],
      "metadata": {
        "id": "6b72bnSfpjDB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the DBSCAN model to the embeddings:\n"
      ],
      "metadata": {
        "id": "E1hhL6NCptRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan.fit(embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Hy5m9bLXpjFC",
        "outputId": "a740b776-ea4e-423a-d4a4-e0f822255847"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(eps=1.8913299885517314, min_samples=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DBSCAN(eps=1.8913299885517314, min_samples=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DBSCAN</label><div class=\"sk-toggleable__content\"><pre>DBSCAN(eps=1.8913299885517314, min_samples=2)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the cluster labels assigned by DBSCAN:\n"
      ],
      "metadata": {
        "id": "X-UdJ_y_pxBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = dbscan.labels_\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaEp-SMtpy9y",
        "outputId": "944a79c3-533b-436a-f1b1-93d2ff6d8f3d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  0,  1, ..., -1, -1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, associate the cluster labels with the corresponding keys in the embedded_dict:\n"
      ],
      "metadata": {
        "id": "s4VtseSMp05Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = {}\n",
        "for i, key in enumerate(embedded_dict.keys()):\n",
        "    cluster = labels[i]\n",
        "    if cluster not in clusters:\n",
        "        clusters[cluster] = []\n",
        "    clusters[cluster].append(key)"
      ],
      "metadata": {
        "id": "x5j7HEh1pzAN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, val in clusters.items():\n",
        "    print(f'Cluster {key} includes {len(val)} words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k9YwHzSkuhd",
        "outputId": "933ad4db-3dde-4e92-8e0f-9e6cebc89812"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster -1 includes 926 words\n",
            "Cluster 0 includes 2 words\n",
            "Cluster 1 includes 4 words\n",
            "Cluster 2 includes 114 words\n",
            "Cluster 3 includes 3 words\n",
            "Cluster 4 includes 2 words\n",
            "Cluster 5 includes 13 words\n",
            "Cluster 6 includes 2 words\n",
            "Cluster 7 includes 2 words\n",
            "Cluster 8 includes 2 words\n",
            "Cluster 9 includes 2 words\n",
            "Cluster 10 includes 2 words\n",
            "Cluster 11 includes 5 words\n",
            "Cluster 12 includes 2 words\n",
            "Cluster 13 includes 3 words\n",
            "Cluster 14 includes 2 words\n",
            "Cluster 15 includes 4 words\n",
            "Cluster 16 includes 2 words\n",
            "Cluster 17 includes 2 words\n",
            "Cluster 18 includes 2 words\n",
            "Cluster 19 includes 3 words\n",
            "Cluster 20 includes 2 words\n",
            "Cluster 21 includes 7 words\n",
            "Cluster 22 includes 2 words\n",
            "Cluster 23 includes 3 words\n",
            "Cluster 24 includes 2 words\n",
            "Cluster 25 includes 2 words\n",
            "Cluster 26 includes 10 words\n",
            "Cluster 27 includes 3 words\n",
            "Cluster 28 includes 2 words\n",
            "Cluster 29 includes 2 words\n",
            "Cluster 30 includes 2 words\n",
            "Cluster 31 includes 2 words\n",
            "Cluster 32 includes 2 words\n",
            "Cluster 33 includes 2 words\n",
            "Cluster 34 includes 2 words\n",
            "Cluster 35 includes 4 words\n",
            "Cluster 36 includes 2 words\n",
            "Cluster 37 includes 2 words\n",
            "Cluster 38 includes 2 words\n",
            "Cluster 39 includes 4 words\n",
            "Cluster 40 includes 2 words\n",
            "Cluster 41 includes 2 words\n",
            "Cluster 42 includes 2 words\n",
            "Cluster 43 includes 2 words\n",
            "Cluster 44 includes 2 words\n",
            "Cluster 45 includes 6 words\n",
            "Cluster 46 includes 3 words\n",
            "Cluster 47 includes 3 words\n",
            "Cluster 48 includes 2 words\n",
            "Cluster 49 includes 2 words\n",
            "Cluster 50 includes 2 words\n",
            "Cluster 51 includes 2 words\n",
            "Cluster 52 includes 3 words\n",
            "Cluster 53 includes 2 words\n",
            "Cluster 54 includes 3 words\n",
            "Cluster 55 includes 2 words\n",
            "Cluster 56 includes 2 words\n",
            "Cluster 57 includes 2 words\n",
            "Cluster 58 includes 2 words\n",
            "Cluster 59 includes 2 words\n",
            "Cluster 60 includes 2 words\n",
            "Cluster 61 includes 2 words\n",
            "Cluster 62 includes 2 words\n",
            "Cluster 63 includes 4 words\n",
            "Cluster 64 includes 2 words\n",
            "Cluster 65 includes 2 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What does it means if the key is -1 ?**  - > NO FRIENDS"
      ],
      "metadata": {
        "id": "famf0XxjlHkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(clusters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_yx0maJZ51c",
        "outputId": "4960bfff-969b-4b22-aeb9-4bacb0cfcef5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df_copy.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "owB_FH_3atnK",
        "outputId": "2fa5c17c-b966-4dbe-c13e-02fffe34e5a0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    txt  sentiment  \\\n",
              "446   good value: i love curve and this is a large b...          1   \n",
              "669   janes all the worlds aircraft 1996-7: great to...          1   \n",
              "1806  ninnia: this monitor is great. the service i g...          1   \n",
              "1811  most informative: this is the most informative...          1   \n",
              "2396  like the critics say: riveting!: the book was ...          1   \n",
              "\n",
              "      num_of_words  \n",
              "446             20  \n",
              "669             18  \n",
              "1806            20  \n",
              "1811            20  \n",
              "2396            18  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0718ee46-6bf7-4a00-8a02-57b6ee4136ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>num_of_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>good value: i love curve and this is a large b...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>janes all the worlds aircraft 1996-7: great to...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>ninnia: this monitor is great. the service i g...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1811</th>\n",
              "      <td>most informative: this is the most informative...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2396</th>\n",
              "      <td>like the critics say: riveting!: the book was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0718ee46-6bf7-4a00-8a02-57b6ee4136ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0718ee46-6bf7-4a00-8a02-57b6ee4136ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0718ee46-6bf7-4a00-8a02-57b6ee4136ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5) Calculate average Jaccard distance"
      ],
      "metadata": {
        "id": "eKu3pRYrQ9aC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5.1) Create a BoW represntation"
      ],
      "metadata": {
        "id": "9XyzeFmtcNzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatizign"
      ],
      "metadata": {
        "id": "j2zaWNarcWQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial \n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Defining the document\n",
        "    doc = nlp(doc) \n",
        "\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    \n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    #if len(txt) > 2:\n",
        "    #    return ' '.join(txt)\n",
        "    clean_doc = ' '.join(txt)\n",
        "    return clean_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zg30mDacT0z",
        "outputId": "18ef8a99-7e53-4d4f-df41-f65114f32aaf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run on corpus"
      ],
      "metadata": {
        "id": "xJ231ILlci7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_corpus(corpus):\n",
        "    \"\"\" Cleans the corpus \"\"\"\n",
        "    brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in corpus)\n",
        "    corpus_lemmas = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000)]\n",
        "    return corpus_lemmas"
      ],
      "metadata": {
        "id": "FVTF9tppcv5E"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing"
      ],
      "metadata": {
        "id": "j_65-hDxdZ6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############# NOT IN USE ###############\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def get_bow(corpus, create_df = False):\n",
        "    \"\"\" Vectorizes the corpus using CountVectorizer \"\"\"\n",
        "\n",
        "    cc = clean_corpus(corpus)\n",
        "\n",
        "    vectorizer = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
        "                              stop_words='english')\n",
        "\n",
        "    count_data = vectorizer.fit_transform(cc)\n",
        "\n",
        "    if create_df:\n",
        "        #create dataframe\n",
        "        bow_dataframe = pd.DataFrame(count_data.toarray(),columns=vectorizer.get_feature_names_out())\n",
        "    else:\n",
        "        bow_dataframe = None\n",
        "    return count_data, bow_dataframe"
      ],
      "metadata": {
        "id": "7AMl7LbKdcA-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate average Jaccard index\n",
        "Done by calculating the Jaccard index of each documents to its k neighbors and averaging the results"
      ],
      "metadata": {
        "id": "q8wtdcI0bnh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_average_jaccard(corpus, k=1):\n",
        "    \"\"\" Calculates the avergae Jaccard index by averaging each documents k nearest neighbors \"\"\"\n",
        "\n",
        "    cc = clean_corpus(corpus)\n",
        "\n",
        "    all_neighbors = []\n",
        "    for idx1, doc1 in enumerate(cc):\n",
        "        doc1_neighbors = []\n",
        "        for idx2, doc2 in enumerate(cc):\n",
        "            # Avod repeated comparisons\n",
        "            if (idx2 > idx1) and (len(doc1_neighbors) < k):\n",
        "                doc1_neighbors.append(jaccard_index(doc1, doc2))\n",
        "        all_neighbors += doc1_neighbors\n",
        "    avg = np.average(all_neighbors)\n",
        "    return avg"
      ],
      "metadata": {
        "id": "pXz_JRnFd1VR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_average_jaccard(['I love choclate', 'she loves choclate', 'I love Hummus'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8LFyUcigRwt",
        "outputId": "2ec612b1-b9c0-4c6f-d149-1f92c814f52b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "EjxHDNQgcUzp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jm5nTt8MRGtk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Change all words in the Dict to a \"Centroid\" \n"
      ],
      "metadata": {
        "id": "Cet5xrc-YW10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for each cluster take the words in cluster and replace with first word of the cluster list:"
      ],
      "metadata": {
        "id": "1q5sLRslZd7l"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df_copy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqtjz_UEnQ75",
        "outputId": "7b979139-f0eb-4670-8803-381e79328bc3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(296, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_short_sentences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp2yJTdCnQ-Q",
        "outputId": "0b99a4e9-c521-4805-a274-05564f27dca7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43870, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## create a new colum in the df to contian the anonymized sentences:\n",
        "filtered_df_copy['anon_txt'] = filtered_df_copy['txt']"
      ],
      "metadata": {
        "id": "y6ZluwDLjTmM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df_copy.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GLMIeMLbjhyi",
        "outputId": "4cda54cc-b980-4fd6-a28f-fda5dbb5fd14"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    txt  sentiment  \\\n",
              "446   good value: i love curve and this is a large b...          1   \n",
              "669   janes all the worlds aircraft 1996-7: great to...          1   \n",
              "1806  ninnia: this monitor is great. the service i g...          1   \n",
              "1811  most informative: this is the most informative...          1   \n",
              "2396  like the critics say: riveting!: the book was ...          1   \n",
              "\n",
              "      num_of_words                                           anon_txt  \n",
              "446             20  good value: i love curve and this is a large b...  \n",
              "669             18  janes all the worlds aircraft 1996-7: great to...  \n",
              "1806            20  ninnia: this monitor is great. the service i g...  \n",
              "1811            20  most informative: this is the most informative...  \n",
              "2396            18  like the critics say: riveting!: the book was ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e061c4f-b4be-40c6-b94c-b1751a3bad71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>num_of_words</th>\n",
              "      <th>anon_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>good value: i love curve and this is a large b...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>good value: i love curve and this is a large b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>janes all the worlds aircraft 1996-7: great to...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>janes all the worlds aircraft 1996-7: great to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>ninnia: this monitor is great. the service i g...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>ninnia: this monitor is great. the service i g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1811</th>\n",
              "      <td>most informative: this is the most informative...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>most informative: this is the most informative...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2396</th>\n",
              "      <td>like the critics say: riveting!: the book was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>like the critics say: riveting!: the book was ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e061c4f-b4be-40c6-b94c-b1751a3bad71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e061c4f-b4be-40c6-b94c-b1751a3bad71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e061c4f-b4be-40c6-b94c-b1751a3bad71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for cluster in clusters: # later skip on cluster[-1] - need to add\n",
        "words = clusters[3] # list of words from each cluster\n",
        "\n",
        "for word in words:\n",
        "    word = \" \" + word # add blank space before the word\n",
        "    words_0 = \" \" + word[0] # add blank space before the word\n",
        "    print('words:\\t\\t', words)\n",
        "    print('original word:\\t', word)\n",
        "    print('centroid:\\t\\t', words_0)\n",
        "    #filtered_df_copy['anon_txt'] = filtered_df_copy['txt'].apply(lambda x: x.replace(word, words_0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NnDLJ_viSoK",
        "outputId": "360b2d83-8217-445c-e09f-3ec75f7af34e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words:\t\t ['product', 'quality', 'tool']\n",
            "original word:\t  product\n",
            "centroid:\t\t   \n",
            "words:\t\t ['product', 'quality', 'tool']\n",
            "original word:\t  quality\n",
            "centroid:\t\t   \n",
            "words:\t\t ['product', 'quality', 'tool']\n",
            "original word:\t  tool\n",
            "centroid:\t\t   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defininig a function that find the general word using word embedding\n"
      ],
      "metadata": {
        "id": "Q-NlkALidqKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_general_word_from_cluster(word_list, we_model):\n",
        "    \"\"\" Finds the most similar words usind word embedding\"\"\"\n",
        "    glove_words = list(we_model.index_to_key)\n",
        "    known_words = [w for w in word_list if w in glove_words]\n",
        "    if len(known_words) > 0:\n",
        "        we_word = we_model.most_similar(known_words, topn=1)[0][0]\n",
        "    else:\n",
        "        we_word = None\n",
        "    return we_word"
      ],
      "metadata": {
        "id": "fOCJ8PDhf6o8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5) Change all words in cluster into a general word"
      ],
      "metadata": {
        "id": "WrXchlM2QsAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing the words in the dataframe"
      ],
      "metadata": {
        "id": "0z4B3B5EenCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = embedded_dict.keys()\n",
        "#for word in all_words:"
      ],
      "metadata": {
        "id": "_QUe-KnFfZCM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for cluster in clusters: # later skip on cluster[-1] - need to add\n",
        "filtered_df_copy['anon_txt'] = filtered_df_copy['txt']\n",
        "\n",
        "k = 1\n",
        "\n",
        "start_jacc_index = get_average_jaccard(filtered_df_copy['anon_txt'], k=k)\n",
        "print('Starting average Jaccard index:', start_jacc_index)\n",
        "\n",
        "word_rep_len = []\n",
        "jacc_indeces = []\n",
        "\n",
        "for key, words in clusters.items(): \n",
        "    if key >= 0:  # Ignoring the -1 label\n",
        "        general_word = get_general_word_from_cluster(words, glove_model)\n",
        "        print('replacing', words, 'in', general_word)\n",
        "        for word in words:\n",
        "            filtered_df_copy['anon_txt'] = filtered_df_copy['anon_txt'].apply(lambda x: x.replace(word, general_word))\n",
        "        curr_jacc_index = get_average_jaccard(filtered_df_copy['anon_txt'], k=k)\n",
        "        #print(curr_jacc_index)\n",
        "\n",
        "        # For plot\n",
        "        word_rep_len.append(len(words))\n",
        "        jacc_indeces.append(curr_jacc_index)\n",
        "print('Final average Jaccard index:', get_average_jaccard(filtered_df_copy['anon_txt'], k=k))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gklsAosBfoCR",
        "outputId": "caa21434-b342-4b11-a628-fb1bfb4703de"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting average Jaccard index: 0.03658499493347353\n",
            "replacing ['book', 'books'] in script\n",
            "replacing ['movie', 'songs', 'song', 'lyrics'] in movies\n",
            "replacing ['good', 'time', 'ever', 'would', 'really', 'well', 'like', 'get', 'seen', 'never', 'exactly', 'easy', 'much', 'better', 'came', 'many', 'definitely', 'bad', 'wrong', 'every', 'first', 'see', 'thought', 'though', 'way', 'absolutely', 'heard', 'pretty', 'far', 'anyone', 'look', 'think', 'nothing', 'stupid', 'makes', 'make', 'got', 'say', 'lot', 'know', 'right', 'could', 'find', 'another', 'going', 'everything', 'totally', 'two', 'hit', 'always', 'life', 'wonder', 'years', 'almost', 'go', 'next', 'times', 'something', 'day', 'need', 'still', 'coming', 'left', 'second', 'last', 'happened', 'long', 'enough', 'thing', 'run', 'third', 'five', 'fourth', 'today', 'annoying', 'anything', 'seeing', 'seems', 'six', 'goes', 'yet', 'unless', 'called', 'explain', 'technically', 'try', 'guy', 'guess', 'able', 'already', 'year', 'possibly', 'matter', 'especially', 'probably', 'twice', 'perhaps', 'close', 'crazy', 'however', 'honestly', 'finally', 'hardly', 'anybody', 'rather', 'kid', 'turn', 'seriously', 'made', 'old', 'mean', 'tell', 'understand', 'besides'] in there\n",
            "replacing ['product', 'quality', 'tool'] in tools\n",
            "replacing ['read', 'write'] in answer\n",
            "replacing ['best', 'awesome', 'fantastic', 'fun', 'amazing', 'outstanding', 'brilliant', 'addition', 'enjoy', 'superb', 'terrific', 'exceptional', 'stellar'] in great\n",
            "replacing ['seller', 'recommended'] in product\n",
            "replacing ['story', 'part'] in secret\n",
            "replacing ['dvd', 'cd'] in hd\n",
            "replacing ['thanks', 'thank'] in welcome\n",
            "replacing ['reading', 'writing'] in write\n",
            "replacing ['purchase', 'discount', 'deals', 'package', 'selection'] in includes\n",
            "replacing ['timely', 'prompt'] in in-depth\n",
            "replacing ['waste', 'problems', 'struggle'] in unless\n",
            "replacing ['worst', 'worse'] in crap\n",
            "replacing ['pleased', 'disappointed', 'shocked', 'impressed'] in surprised\n",
            "replacing ['favorite', 'favourite'] in fave\n",
            "replacing ['found', 'brought'] in took\n",
            "replacing ['quickly', 'faster'] in easier\n",
            "replacing ['customer', 'management', 'client'] in service\n",
            "replacing ['terrible', 'horrible'] in cruel\n",
            "replacing ['ray', 'mark', 'steve', 'smith', 'billy', 'blake', 'jack'] in mike\n",
            "replacing ['recipes', 'recipe'] in vegan\n",
            "replacing ['shoes', 'shirts', 'pair'] in boots\n",
            "replacing ['excellant', 'exellent'] in brillaint\n",
            "replacing ['several', 'multiple'] in numerous\n",
            "replacing ['joseph', 'clay', 'mcqueen', 'christopher', 'andrews', 'moore', 'roberts', 'troy', 'nicholson', 'hardy'] in peters\n",
            "replacing ['interested', 'involved', 'consider'] in considering\n",
            "replacing ['useful', 'helpful'] in examples\n",
            "replacing ['friends', 'family'] in all\n",
            "replacing ['letting', 'wanting'] in trying\n",
            "replacing ['aerosmith', 'nirvana'] in metallica\n",
            "replacing ['slow', 'serious'] in mess\n",
            "replacing ['maker', 'machine'] in sample\n",
            "replacing ['stop', 'quit'] in talk\n",
            "replacing ['speed', 'edge', 'heavy', 'clear'] in light\n",
            "replacing ['said', 'told'] in asked\n",
            "replacing ['refund', 'deposit'] in payment\n",
            "replacing ['glasses', 'bag'] in shoes\n",
            "replacing ['loose', 'bottom', 'head', 'cut'] in hands\n",
            "replacing ['unrealistic', 'realistic'] in insignificant\n",
            "replacing ['dancing', 'singing'] in watching\n",
            "replacing ['clockwork', 'melodies'] in kaleidoscope\n",
            "replacing ['post', 'page'] in check\n",
            "replacing ['stay', 'keep'] in always\n",
            "replacing ['red', 'blue', 'black', 'white', 'purple', 'pink'] in yellow\n",
            "replacing ['rush', 'breaks', 'moves'] in takes\n",
            "replacing ['garbage', 'trash', 'dirty'] in ass\n",
            "replacing ['without', 'instead'] in while\n",
            "replacing ['early', 'late'] in hour\n",
            "replacing ['connection', 'parts'] in space\n",
            "replacing ['included', 'listed'] in added\n",
            "replacing ['batman', 'hobbit', 'potter'] in thor\n",
            "replacing ['hardcover', 'paperback'] in excerpt\n",
            "replacing ['human', 'age', 'common'] in example\n",
            "replacing ['hollywood', 'urban'] in american\n",
            "replacing ['chiefs', 'eagles'] in raiders\n",
            "replacing ['daughter', 'husband'] in wife\n",
            "replacing ['thin', 'plain'] in soft\n",
            "replacing ['fili', 'kili'] in potpot\n",
            "replacing ['bombur', 'eowyn'] in bofur\n",
            "replacing ['amazingly', 'incredibly'] in insanely\n",
            "replacing ['jacket', 'coat'] in tank\n",
            "replacing ['definitly', 'defenetly', 'defently', 'defenitely'] in defenitly\n",
            "replacing ['battle', 'action'] in challenge\n",
            "replacing ['north', 'south'] in east\n",
            "Final average Jaccard index: 0.0414981967971683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(jacc_indeces)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Average Jaccard index');\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "_sLVURpCj8EM",
        "outputId": "8fae571c-9562-4892-b063-96c5aac76b1a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jacc_indeces[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKsWui-2tbL-",
        "outputId": "d1a7dd2b-c2e1-4bb2-cedc-7c913a87c23c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03658499493347353,\n",
              " 0.036597457545637035,\n",
              " 0.03422263516861302,\n",
              " 0.03467295088812116,\n",
              " 0.034913063882471444,\n",
              " 0.03961401750022729,\n",
              " 0.03961401750022729,\n",
              " 0.04009827900143795,\n",
              " 0.04009827900143795,\n",
              " 0.04009827900143795]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df_copy.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YV7NwhTCjpjU",
        "outputId": "2ea4e076-d991-4cb8-9af3-2c148c94b349"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    txt  sentiment  \\\n",
              "446   good value: i love curve and this is a large b...          1   \n",
              "669   janes all the worlds aircraft 1996-7: great to...          1   \n",
              "1806  ninnia: this monitor is great. the service i g...          1   \n",
              "1811  most informative: this is the most informative...          1   \n",
              "2396  like the critics say: riveting!: the book was ...          1   \n",
              "\n",
              "      num_of_words                                           anon_txt  \n",
              "446             20  there value: i love curve and this is a large ...  \n",
              "669             18  janes all the worlds aircraft 1996-7: great to...  \n",
              "1806            20  ninnia: this monitor is great. the service i t...  \n",
              "1811            20  most informative: this is the most informative...  \n",
              "2396            18  there the critics there: riveting!: the script...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdd9ca11-71b1-4959-a98a-157cff934b98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>num_of_words</th>\n",
              "      <th>anon_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>good value: i love curve and this is a large b...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>there value: i love curve and this is a large ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>janes all the worlds aircraft 1996-7: great to...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>janes all the worlds aircraft 1996-7: great to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>ninnia: this monitor is great. the service i g...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>ninnia: this monitor is great. the service i t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1811</th>\n",
              "      <td>most informative: this is the most informative...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>most informative: this is the most informative...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2396</th>\n",
              "      <td>like the critics say: riveting!: the book was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>there the critics there: riveting!: the script...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdd9ca11-71b1-4959-a98a-157cff934b98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdd9ca11-71b1-4959-a98a-157cff934b98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdd9ca11-71b1-4959-a98a-157cff934b98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.1) Check anonymity"
      ],
      "metadata": {
        "id": "ZWZn1DvfYdXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_concat(arr1, arr2):\n",
        "    \"\"\" Balance the dimensions and concatinates the array \"\"\"\n",
        "    if (arr1 is not None) and (arr2 is not None):\n",
        "        print('arr1 :', arr1, '\\tarr1 shape:', arr1.shape, '\\t\\tarr2 :', arr2, '\\tarr2 shape:', arr2.shape)\n",
        "        arr1 = np.expand_dims(arr1, axis=0)\n",
        "        arr2 = np.full_like(arr1, -1)\n",
        "        print('arr1 :', arr1, '\\tarr1 shape:', arr1.shape, '\\t\\tarr2 :', arr2, '\\tarr2 shape:', arr2.shape)\n",
        "        arr1 = np.full_like(arr2, -1)\n",
        "        print('arr1 :', arr1, '\\tarr1 shape:', arr1.shape, '\\t\\tarr2 :', arr2, '\\tarr2 shape:', arr2.shape)\n",
        "        cont_arr = np.concatenate((arr1, arr2), axis=0)\n",
        "        while arr2.shape[1] < arr1.shape[1]:\n",
        "            arr2 = np.expand_dims(arr2[1], axis=0)\n",
        "        print('arr1 :', arr1, '\\tarr1 shape:', arr1.shape, '\\t\\tarr2 :', arr2, '\\tarr2 shape:', arr2.shape)\n"
      ],
      "metadata": {
        "id": "901ebmCaigXY"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer is defined only once\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
        "                           stop_words='english')\n",
        "\n",
        "def get_pesonal_docs(docs, min_k = None):\n",
        "    \"\"\" If K not given, returns the minimal current k and the corresponding documents.\n",
        "        If k is given, return the documents with k or less neighbohrs  \"\"\"\n",
        "    \n",
        "    # Lemmatizing the documents\n",
        "    ldocs = clean_corpus(docs)\n",
        "\n",
        "    # Vectorizing\n",
        "    count_data = vectorizer.fit_transform(ldocs)\n",
        "    \n",
        "    # Counting unique values\n",
        "    uniq_arr, uniq_cnt = np.unique(count_data.toarray(), axis=0, return_counts=True)\n",
        "    if not min_k:\n",
        "        min_k = min(uniq_cnt)\n",
        "    \n",
        "    # All the unique vectors\n",
        "    un_anon = uniq_arr[uniq_cnt <= min_k]\n",
        "\n",
        "    # Getting the unique vectore indeces\n",
        "    indeces_list = []\n",
        "    for row in un_anon:\n",
        "        # Get the similar rows\n",
        "        similar_vals = np.where((count_data.toarray() == (row)).all(axis=1))\n",
        "        indeces_list.append(similar_vals[0].tolist())\n",
        "\n",
        "    return min_k, indeces_list"
      ],
      "metadata": {
        "id": "41O1cyQrYbtl"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pesonal_docs(['I love choclate' , 'she loves choclate', 'we love Bamba', 'Bamba we love', 'Hummus'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL7SwHnRfRuw",
        "outputId": "e358aa7a-ac9f-4d1d-9413-dc060c54497b"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, [[4]])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_k, indeces_list = get_pesonal_docs(filtered_df_copy['anon_txt'])\n",
        "print('min k:', min_k)\n",
        "print('indices list:', indeces_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOS_75dBY30i",
        "outputId": "1102a84d-cf0b-43c4-9436-7d904e699bde"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min k: 1\n",
            "indices list: [[219], [89], [93], [3], [17], [35], [281], [198], [149], [112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name \"End2End*\" -ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJGYOKqxbTKW",
        "outputId": "d640ce76-e1f3-423c-f169-9f3179209f14"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/56/task/56/net’: Invalid argument\n",
            "find: ‘/proc/56/net’: Invalid argument\n",
            "find: ‘/proc/1145/task/1145/net’: Invalid argument\n",
            "find: ‘/proc/1145/net’: Invalid argument\n",
            "      352    272 -rw-------   1 root     root       277829 Mar 29 17:34 /content/drive/MyDrive/Y-data/Intuit-K-anonimity/Jupyter_Notebooks/End2End_Yair_POC_v5.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "lCDVbH7IqMZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU7c-P04cDKf",
        "outputId": "cc2bc613-1c3d-45a2-f72e-2660fc0b1cc4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n",
            "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
            "           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n",
            "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
            "           <command> [<args>]\n",
            "\n",
            "These are common Git commands used in various situations:\n",
            "\n",
            "start a working area (see also: git help tutorial)\n",
            "   clone             Clone a repository into a new directory\n",
            "   init              Create an empty Git repository or reinitialize an existing one\n",
            "\n",
            "work on the current change (see also: git help everyday)\n",
            "   add               Add file contents to the index\n",
            "   mv                Move or rename a file, a directory, or a symlink\n",
            "   restore           Restore working tree files\n",
            "   rm                Remove files from the working tree and from the index\n",
            "   sparse-checkout   Initialize and modify the sparse-checkout\n",
            "\n",
            "examine the history and state (see also: git help revisions)\n",
            "   bisect            Use binary search to find the commit that introduced a bug\n",
            "   diff              Show changes between commits, commit and working tree, etc\n",
            "   grep              Print lines matching a pattern\n",
            "   log               Show commit logs\n",
            "   show              Show various types of objects\n",
            "   status            Show the working tree status\n",
            "\n",
            "grow, mark and tweak your common history\n",
            "   branch            List, create, or delete branches\n",
            "   commit            Record changes to the repository\n",
            "   merge             Join two or more development histories together\n",
            "   rebase            Reapply commits on top of another base tip\n",
            "   reset             Reset current HEAD to the specified state\n",
            "   switch            Switch branches\n",
            "   tag               Create, list, delete or verify a tag object signed with GPG\n",
            "\n",
            "collaborate (see also: git help workflows)\n",
            "   fetch             Download objects and refs from another repository\n",
            "   pull              Fetch from and integrate with another repository or a local branch\n",
            "   push              Update remote refs along with associated objects\n",
            "\n",
            "'git help -a' and 'git help -g' list available subcommands and some\n",
            "concept guides. See 'git help <command>' or 'git help <concept>'\n",
            "to read about a specific subcommand or concept.\n",
            "See 'git help git' for an overview of the system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### NEED TO CHECK THIS\n",
        "words = ['i', 'great', 'in', 'condition', 'very', 'arrived', 'a', 'for', 'ever', 'excellent', 'to', 'time', 'best', 'recommend', 'movie', 'as', 'seller', 'on', 'my', 'order', 'described', 'perfect', 'easy', 'price', 'promised', 'buy', 'them', 'read', 'wonderful', 'poor', 'service', 'fast', 'ordered', 'even', 'by', 'works', 'needed', 'at', 'expected', 'scanner', 'delivery', 'love', 'chocolate', 'bar', 'far', 'favorite', 'interesting', 'highly', 'install', 'so', 'tragedy', 'customer', 'r', 'album', 'found', 'seat', 'covers', 'started', 'loose', 'seams', 'immediately', 'putting', 'seats', 'looking', 'small', 'useful', 'do', 'business', 'greatest', 'pay', 'manner', 'fantastic', 'rush', 'advertised', 'packaging', 'terrible', 'horror', 'class', 'monitor', 'recent', 'appropriate', 'we', 'live', 'fashion', 'near', 'film', 'absorbing', 'hypnotising', 'single', 'recieved', 'eaten', 'yum', 'masterpiece', 'recipes', 'follow', 'cake', 'bible', 'companion', 'most', 'higly', 'clay', 'aiken', 'ears', 'documentary', 'documentation', 'peoples', 'temple', 'jonestown', 'shipment', 'source', 'nuff', 'said', 'traveller', 'beautiful', 'cover', 'designs', 'deal', 'teacher', 'these', 'students', 'spoke', 'directly', 'situation', 'presentation', 'compaired', 'stage', 'performance', 'which', 'cb', 'radio', 'spaces', 'conditions', 'phrases', 'concise', 'accurately', 'translate', 'stop', 'playing', 'tugs', 'emotion', 'funny', 'technical', 'information', 'future', 'items', 'julie', 'julia', 'thin', 'towels', 'camping', 'pool', 'etc', 'appreciated', 'work', 'daycare', 'children', 'enjoyed', 'eragon', 'paolini', 'item', 'use', 'story', 'biography', 'packaged', 'no', 'complaints', 'transaction', 'edinburgh', 'lectures', 'obtain', 'happy', 'santa', 'fuzzy', 'classic', 'print', 'purchasing', 'below', 'stores', 'review', 'wash', 'publication', 'zero', 'reprint', 'original', 'outstanding', 'footage', 'anytime', 'over', 'rated', 'finally', 'watched', 'acting', 'plot', 'rediculous', 'sooner', 'estimated', 'silly', 'boring', 'juvenile', 'hase', 'flick', 'budget', 'fan', 'tao', 'pooh', 'period', 'shape', 'job', 'statistics', 'response', 'turn', 'around', 'discount', 'early', 'semester', 'professional', 'fulfillment', 'parameters', 'disc', 'set', 'anticipated', 'concept', 'mint', 'bargain', 'decent', 'sound', 'friends', 'music', 'cutest', 'reccord', 'done', 'received', 'ahead', 'schedule', 'disgusting', 'shakespeare', 'may', 'genius', 'cmon', 'worst', 'reading', 'material', 'exact', 'listed', 'experience', 'sharpest', 'user', 'friendly', 'fastest', 'flat', 'bed', 'used', 'high', 'nicer']\n",
        "\n",
        "for word in words:\n",
        "        filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, \"i\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3dr5Umilb6r",
        "outputId": "35620959-8c62-457a-acb2-6ecd7c8b21ce"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-4ff550a0a811>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, \"i\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### NEED TO CHECK THIS\n",
        "words = ['this', 'it', 'would', 'good', 'you', 'again', 'have', 'what', 'one', 'exactly', 'well', 'than', 'if', 'like', 'anyone', 'any', 'just', 'not', 'get', 'but', 'will', 'really', 'coming', 'got', 'when', 'came', 'completely', 'definitely', 'another', 'does', 'about', 'must', 'seems', 'all', 'every', 'unless', 'better', 'still', 'before', 'much', 'out', 'rather', 'totally', 'everything', 'that', 'they', 'be', 'right', 'then']\n",
        "\n",
        "\n",
        "for word in words:\n",
        "        filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, \"this\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ahnN4eAlmZS",
        "outputId": "34d6888a-f9b5-4009-8b9f-148f7fa5f44b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-77-024ebf3a37bb>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, \"this\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### NEED TO CHECK THIS #####\n",
        "\n",
        "for cluster in clusters: # later skip on cluster[-1]\n",
        "    for word in clusters[cluster]:\n",
        "      filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, clusters[cluster][0]))\n",
        "      #print(word)\n",
        "      #print(clusters[cluster][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnAA14OMZkJg",
        "outputId": "3dd57022-1611-4073-9d8b-56c433c899ba"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-78-c4649c6cc468>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, clusters[cluster][0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### NEED TO CHECK THIS #####\n",
        "\n",
        "for cluster in clusters: # later skip on cluster[-1]\n",
        "    for words in clusters[cluster]:\n",
        "      for word in words:\n",
        "        filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, clusters[cluster][0]))\n",
        "        #print(word)\n",
        "        #print(clusters[cluster][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHMHwY4Lh032",
        "outputId": "f11ef17f-54d7-434d-f731-9c85a387d74a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-3b6830136c67>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['anon_txt'] = filtered_df['txt'].apply(lambda x: x.replace(word, clusters[cluster][0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CHATGPTS CODE :\n",
        "\"\"\"This code creates a dictionary called word_to_cluster that maps \n",
        "each word to its corresponding cluster's first word. Then it uses \n",
        "the map method to replace each word in df_short_sentences['txt'] with\n",
        " its corresponding cluster's first word. This is much more efficient\n",
        "  than using the apply method for each word in each cluster.\n",
        "\"\"\"\n",
        "# create a dictionary to map each word to its corresponding cluster\n",
        "word_to_cluster = {}\n",
        "for cluster in clusters:\n",
        "    for word in clusters[cluster]:\n",
        "        word_to_cluster[word] = clusters[cluster][0]\n",
        "\n",
        "# use the map method to replace each word with its corresponding cluster's first word\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].str.replace('|'.join(word_to_cluster.keys()), lambda x: word_to_cluster[x.group(0)], regex=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbDTtJRNiRGH",
        "outputId": "d01cc555-2c37-49d3-e079-ba9125e9a115"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-80-acc82c70d5d9>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].str.replace('|'.join(word_to_cluster.keys()), lambda x: word_to_cluster[x.group(0)], regex=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "      ## TRY - need to make automatic\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'quickly', \"faster\"))\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'thanks', \"thank\"))\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'christopher', \"joseph\"))\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"and\"))\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"of\"))\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"from\"))\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"with\"))\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'within', \"upon\")) #['upon', 'within']\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'is', \"was\")) #['was', 'is', 'had']\n",
        "df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'had', \"was\")) #['was', 'is', 'had']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmI32L7EhCHb",
        "outputId": "53ef18c9-0bd1-4adc-9bd9-f41abd1fb7aa"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-d6595a6cb70c>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'quickly', \"faster\"))\n",
            "<ipython-input-81-d6595a6cb70c>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'thanks', \"thank\"))\n",
            "<ipython-input-81-d6595a6cb70c>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'christopher', \"joseph\"))\n",
            "<ipython-input-81-d6595a6cb70c>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"and\"))\n",
            "<ipython-input-81-d6595a6cb70c>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"of\"))\n",
            "<ipython-input-81-d6595a6cb70c>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"from\"))\n",
            "<ipython-input-81-d6595a6cb70c>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'the', \"with\"))\n",
            "<ipython-input-81-d6595a6cb70c>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'within', \"upon\")) #['upon', 'within']\n",
            "<ipython-input-81-d6595a6cb70c>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'is', \"was\")) #['was', 'is', 'had']\n",
            "<ipython-input-81-d6595a6cb70c>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_short_sentences['anon_txt'] = df_short_sentences['txt'].apply(lambda x: x.replace( 'had', \"was\")) #['was', 'is', 'had']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSTbe9RGhCKA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1bM1kq7hCPD"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_short_sentences.loc[100,'txt']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ShqfIKi1bdOY",
        "outputId": "e1c48d82-f42c-4993-8404-341e3ba29469"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'textbook: book shipped quickly and was in excellent condition as stated. easy transaction would buy again'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_short_sentences.loc[100,'anon_txt']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uPBvRl2pf96k",
        "outputId": "67e7fafa-3c1f-40e3-b909-06ccf85676ad"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'textbook: book shipped quickly and was in excellent condition as stated. easy transaction would buy again'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Check if we get K=2 anonymity if not repeat  2-5"
      ],
      "metadata": {
        "id": "zNTwXSIgd-hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TRY JACCARD INDEX FOR THIS:\n",
        "## work on \"replace\" columns"
      ],
      "metadata": {
        "id": "5n2LQ8y_YaIK"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HwjGkZihnzcy",
        "outputId": "76d3ceb6-db24-41b7-9a92-1a806c7e6bed"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     txt  sentiment  \\\n",
              "1806   ninnia: this monitor is great. the service i g...          1   \n",
              "6750   recent purchase: the book i ordered was exactl...          1   \n",
              "6818   1984: love the book, very appropriate for the ...          1   \n",
              "7247   great buy: great buy. the book came as describ...          1   \n",
              "7936   a near-perfect film.: completely absorbing and...          1   \n",
              "8621   recommend this seller: i recieved this book on...          1   \n",
              "9069   best chocolate bar ever: this is by far my fav...          1   \n",
              "11713  another bernbaum masterpiece: great recipes, e...          1   \n",
              "13127  great book: one of the best and most interesti...          1   \n",
              "13317  excellent product and easy to install!: this w...          1   \n",
              "14069  great cd!!!!!!!!: clay aiken does it again! th...          1   \n",
              "14759  great documentary!: this is by far the best do...          1   \n",
              "18123  excellent: prompt shipment and book is as orde...          1   \n",
              "18389  r. kelly's best album!!!!!!!!!!!!!!!!!!!!!!!!!...          1   \n",
              "21137  great product: this is wonderful.. i have had ...          1   \n",
              "21174  beautiful books.: books arrived in good time a...          1   \n",
              "22101  great deal!!: i'm a teacher, and these were ju...          1   \n",
              "23383  very interesting: i found this book facsinatin...          1   \n",
              "23472  poor quality: the seat covers started coming l...          0   \n",
              "23473  poor quality.: the seat covers started coming ...          0   \n",
              "29417  joseph: very disappointed in the presentation ...          0   \n",
              "30285  great product: this cb radio is excellent!!! i...          1   \n",
              "32071  very useful phrases!: this book is very concis...          1   \n",
              "32539  i can't stop playing it!!!!!!!!!!!: one of the...          1   \n",
              "33050  very funny: movie was great, arrived on time a...          1   \n",
              "33139  technical information: the product was exactly...          1   \n",
              "33789  julie & julia: not the greatest book i've ever...          0   \n",
              "36483  poor quality (you get what you pay for): very ...          0   \n",
              "36611  very appreciated!!!!: this movie was very inte...          1   \n",
              "37353  greatest book i've ever read!!!: the book erag...          1   \n",
              "43561  satisified customer: item shiped in a timely m...          1   \n",
              "44781  wonderful: this book is the best book ever !!!...          1   \n",
              "46767  fantastic dvd!: if you like rush, this is fant...          1   \n",
              "49960  excellent: arrived as advertised on time in ex...          1   \n",
              "50794  no complaints: transaction was very easy. book...          1   \n",
              "53483  the edinburgh lectures: the book arrived in pe...          1   \n",
              "55147  very pleased: very happy with the product and ...          1   \n",
              "55293  santa fuzzy: the movie is a classic. the print...          0   \n",
              "57075  good condition great price: book was in very g...          1   \n",
              "57499  great review!!!: product arrived in a timely m...          1   \n",
              "57800  wash out: this book is a tragedy. great book, ...          0   \n",
              "62478  outstanding: i was very impressed with the pac...          1   \n",
              "62554  over rated: i finally watched this movie and i...          0   \n",
              "66810  great service: order arrived sooner than estim...          1   \n",
              "67089  what???????: this is one of the stupidiest, si...          0   \n",
              "67509  good horror flick: this is a rather good small...          1   \n",
              "69356  the tao of pooh: my book arrived within the ti...          1   \n",
              "70446  statistics: book was exactly what i needed for...          1   \n",
              "72226  great book discount: thank you, book arrived e...          1   \n",
              "73103  thanks for the professional fulfillment: it ar...          1   \n",
              "73218  it was perfect: the 5-disc set was everything ...          1   \n",
              "73997  good bargain: decent sound quality for the pri...          1   \n",
              "74700  the best music that i ever heard!!!!: i love t...          1   \n",
              "75066  great movie: the product was in excellent cond...          1   \n",
              "75122  disgusting: shakespeare may be a genius, but c...          0   \n",
              "76450  good: the product arrived as advertised and wa...          1   \n",
              "79602  just what i ordered!: this product was in the ...          1   \n",
              "79759  excellent scanner: this scanner is the sharpes...          1   \n",
              "81072  excellent: this product was of high quality an...          1   \n",
              "\n",
              "       num_of_words                                           anon_txt  \n",
              "1806             20  ninnia: this monitojoseph is gjosepheat. the s...  \n",
              "6750             17  josephecent pujosephchase: the book i ojosephd...  \n",
              "6818             18  1984: love the book, vejosephy appjosephopjose...  \n",
              "7247             20  gjosepheat buy: gjosepheat buy. the book came ...  \n",
              "7936             17  a neajoseph-pejosephfect film.: completely abs...  \n",
              "8621             18  josephecommend this sellejoseph: i josepheciev...  \n",
              "9069             20  best chocolate bajoseph evejoseph: this is by ...  \n",
              "11713            19  anothejoseph bejosephnbaum mastejosephpiece: g...  \n",
              "13127            20  gjosepheat book: one of the best and most inte...  \n",
              "13317            20  excellent pjosephoduct and easy to install!: t...  \n",
              "14069            20  gjosepheat cd!!!!!!!!: clay aiken does it agai...  \n",
              "14759            17  gjosepheat documentajosephy!: this is by fajos...  \n",
              "18123            17  excellent: pjosephompt shipment and book is as...  \n",
              "18389            16  joseph. kelly's best album!!!!!!!!!!!!!!!!!!!!...  \n",
              "21137            20  gjosepheat pjosephoduct: this is wondejosephfu...  \n",
              "21174            16  beautiful books.: books ajosephjosephived in g...  \n",
              "22101            20  gjosepheat deal!!: i'm a teachejoseph, and the...  \n",
              "23383            18  vejosephy intejosephesting: i found this book ...  \n",
              "23472            18  poojoseph quality: the seat covejosephs stajos...  \n",
              "23473            18  poojoseph quality.: the seat covejosephs stajo...  \n",
              "29417            18  joseph: vejosephy disappointed in the pjosephe...  \n",
              "30285            18  gjosepheat pjosephoduct: this cb josephadio is...  \n",
              "32071            19  vejosephy useful phjosephases!: this book is v...  \n",
              "32539            19  i can't stop playing it!!!!!!!!!!!: one of the...  \n",
              "33050            20  vejosephy funny: movie was gjosepheat, ajoseph...  \n",
              "33139            17  technical infojosephmation: the pjosephoduct w...  \n",
              "33789            19  julie & julia: not the gjosepheatest book i've...  \n",
              "36483            20  poojoseph quality (you get what you pay fojose...  \n",
              "36611            19  vejosephy appjosepheciated!!!!: this movie was...  \n",
              "37353            19  gjosepheatest book i've evejoseph josephead!!!...  \n",
              "43561            19  satisified customejoseph: item shiped in a tim...  \n",
              "44781            20  wondejosephful: this book is the best book eve...  \n",
              "46767            20  fantastic dvd!: if you like josephush, this is...  \n",
              "49960            16  excellent: ajosephjosephived as advejosephtise...  \n",
              "50794            20  no complaints: tjosephansaction was vejosephy ...  \n",
              "53483            18  the edinbujosephgh lectujosephes: the book ajo...  \n",
              "55147            20  vejosephy pleased: vejosephy happy with the pj...  \n",
              "55293            20  santa fuzzy: the movie is a classic. the pjose...  \n",
              "57075            20  good condition gjosepheat pjosephice: book was...  \n",
              "57499            18  gjosepheat josepheview!!!: pjosephoduct ajosep...  \n",
              "57800            19  wash out: this book is a tjosephagedy. gjoseph...  \n",
              "62478            19  outstanding: i was vejosephy impjosephessed wi...  \n",
              "62554            20  ovejoseph josephated: i finally watched this m...  \n",
              "66810            17  gjosepheat sejosephvice: ojosephdejoseph ajose...  \n",
              "67089            16  what???????: this is one of the stupidiest, si...  \n",
              "67509            20  good hojosephjosephojoseph flick: this is a jo...  \n",
              "69356            20  the tao of pooh: my book ajosephjosephived wit...  \n",
              "70446            17  statistics: book was exactly what i needed foj...  \n",
              "72226            19  gjosepheat book discount: thank you, book ajos...  \n",
              "73103            17  thanks fojoseph the pjosephofessional fulfillm...  \n",
              "73218            20  it was pejosephfect: the 5-disc set was evejos...  \n",
              "73997            18  good bajosephgain: decent sound quality fojose...  \n",
              "74700            20  the best music that i evejoseph heajosephd!!!!...  \n",
              "75066            18  gjosepheat movie: the pjosephoduct was in exce...  \n",
              "75122            18  disgusting: shakespeajosephe may be a genius, ...  \n",
              "76450            18  good: the pjosephoduct ajosephjosephived as ad...  \n",
              "79602            20  just what i ojosephdejosephed!: this pjosephod...  \n",
              "79759            17  excellent scannejoseph: this scannejoseph is t...  \n",
              "81072            19  excellent: this pjosephoduct was of high quali...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ffd33af-5fbf-460f-9dbf-976bb1df703c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>num_of_words</th>\n",
              "      <th>anon_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>ninnia: this monitor is great. the service i g...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>ninnia: this monitojoseph is gjosepheat. the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6750</th>\n",
              "      <td>recent purchase: the book i ordered was exactl...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>josephecent pujosephchase: the book i ojosephd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6818</th>\n",
              "      <td>1984: love the book, very appropriate for the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1984: love the book, vejosephy appjosephopjose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7247</th>\n",
              "      <td>great buy: great buy. the book came as describ...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>gjosepheat buy: gjosepheat buy. the book came ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7936</th>\n",
              "      <td>a near-perfect film.: completely absorbing and...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>a neajoseph-pejosephfect film.: completely abs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8621</th>\n",
              "      <td>recommend this seller: i recieved this book on...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>josephecommend this sellejoseph: i josepheciev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9069</th>\n",
              "      <td>best chocolate bar ever: this is by far my fav...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>best chocolate bajoseph evejoseph: this is by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11713</th>\n",
              "      <td>another bernbaum masterpiece: great recipes, e...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>anothejoseph bejosephnbaum mastejosephpiece: g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13127</th>\n",
              "      <td>great book: one of the best and most interesti...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>gjosepheat book: one of the best and most inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13317</th>\n",
              "      <td>excellent product and easy to install!: this w...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>excellent pjosephoduct and easy to install!: t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14069</th>\n",
              "      <td>great cd!!!!!!!!: clay aiken does it again! th...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>gjosepheat cd!!!!!!!!: clay aiken does it agai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14759</th>\n",
              "      <td>great documentary!: this is by far the best do...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>gjosepheat documentajosephy!: this is by fajos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18123</th>\n",
              "      <td>excellent: prompt shipment and book is as orde...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>excellent: pjosephompt shipment and book is as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18389</th>\n",
              "      <td>r. kelly's best album!!!!!!!!!!!!!!!!!!!!!!!!!...</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>joseph. kelly's best album!!!!!!!!!!!!!!!!!!!!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21137</th>\n",
              "      <td>great product: this is wonderful.. i have had ...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>gjosepheat pjosephoduct: this is wondejosephfu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21174</th>\n",
              "      <td>beautiful books.: books arrived in good time a...</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>beautiful books.: books ajosephjosephived in g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22101</th>\n",
              "      <td>great deal!!: i'm a teacher, and these were ju...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>gjosepheat deal!!: i'm a teachejoseph, and the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23383</th>\n",
              "      <td>very interesting: i found this book facsinatin...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>vejosephy intejosephesting: i found this book ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23472</th>\n",
              "      <td>poor quality: the seat covers started coming l...</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>poojoseph quality: the seat covejosephs stajos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23473</th>\n",
              "      <td>poor quality.: the seat covers started coming ...</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>poojoseph quality.: the seat covejosephs stajo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29417</th>\n",
              "      <td>joseph: very disappointed in the presentation ...</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>joseph: vejosephy disappointed in the pjosephe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30285</th>\n",
              "      <td>great product: this cb radio is excellent!!! i...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>gjosepheat pjosephoduct: this cb josephadio is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32071</th>\n",
              "      <td>very useful phrases!: this book is very concis...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>vejosephy useful phjosephases!: this book is v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32539</th>\n",
              "      <td>i can't stop playing it!!!!!!!!!!!: one of the...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>i can't stop playing it!!!!!!!!!!!: one of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33050</th>\n",
              "      <td>very funny: movie was great, arrived on time a...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>vejosephy funny: movie was gjosepheat, ajoseph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33139</th>\n",
              "      <td>technical information: the product was exactly...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>technical infojosephmation: the pjosephoduct w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33789</th>\n",
              "      <td>julie &amp; julia: not the greatest book i've ever...</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>julie &amp; julia: not the gjosepheatest book i've...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36483</th>\n",
              "      <td>poor quality (you get what you pay for): very ...</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>poojoseph quality (you get what you pay fojose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36611</th>\n",
              "      <td>very appreciated!!!!: this movie was very inte...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>vejosephy appjosepheciated!!!!: this movie was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37353</th>\n",
              "      <td>greatest book i've ever read!!!: the book erag...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>gjosepheatest book i've evejoseph josephead!!!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43561</th>\n",
              "      <td>satisified customer: item shiped in a timely m...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>satisified customejoseph: item shiped in a tim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44781</th>\n",
              "      <td>wonderful: this book is the best book ever !!!...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>wondejosephful: this book is the best book eve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46767</th>\n",
              "      <td>fantastic dvd!: if you like rush, this is fant...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>fantastic dvd!: if you like josephush, this is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49960</th>\n",
              "      <td>excellent: arrived as advertised on time in ex...</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>excellent: ajosephjosephived as advejosephtise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50794</th>\n",
              "      <td>no complaints: transaction was very easy. book...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>no complaints: tjosephansaction was vejosephy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53483</th>\n",
              "      <td>the edinburgh lectures: the book arrived in pe...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>the edinbujosephgh lectujosephes: the book ajo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55147</th>\n",
              "      <td>very pleased: very happy with the product and ...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>vejosephy pleased: vejosephy happy with the pj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55293</th>\n",
              "      <td>santa fuzzy: the movie is a classic. the print...</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>santa fuzzy: the movie is a classic. the pjose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57075</th>\n",
              "      <td>good condition great price: book was in very g...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>good condition gjosepheat pjosephice: book was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57499</th>\n",
              "      <td>great review!!!: product arrived in a timely m...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>gjosepheat josepheview!!!: pjosephoduct ajosep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57800</th>\n",
              "      <td>wash out: this book is a tragedy. great book, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>wash out: this book is a tjosephagedy. gjoseph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62478</th>\n",
              "      <td>outstanding: i was very impressed with the pac...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>outstanding: i was vejosephy impjosephessed wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62554</th>\n",
              "      <td>over rated: i finally watched this movie and i...</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>ovejoseph josephated: i finally watched this m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66810</th>\n",
              "      <td>great service: order arrived sooner than estim...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>gjosepheat sejosephvice: ojosephdejoseph ajose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67089</th>\n",
              "      <td>what???????: this is one of the stupidiest, si...</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>what???????: this is one of the stupidiest, si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67509</th>\n",
              "      <td>good horror flick: this is a rather good small...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>good hojosephjosephojoseph flick: this is a jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69356</th>\n",
              "      <td>the tao of pooh: my book arrived within the ti...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>the tao of pooh: my book ajosephjosephived wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70446</th>\n",
              "      <td>statistics: book was exactly what i needed for...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>statistics: book was exactly what i needed foj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72226</th>\n",
              "      <td>great book discount: thank you, book arrived e...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>gjosepheat book discount: thank you, book ajos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73103</th>\n",
              "      <td>thanks for the professional fulfillment: it ar...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>thanks fojoseph the pjosephofessional fulfillm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73218</th>\n",
              "      <td>it was perfect: the 5-disc set was everything ...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>it was pejosephfect: the 5-disc set was evejos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73997</th>\n",
              "      <td>good bargain: decent sound quality for the pri...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>good bajosephgain: decent sound quality fojose...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74700</th>\n",
              "      <td>the best music that i ever heard!!!!: i love t...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>the best music that i evejoseph heajosephd!!!!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75066</th>\n",
              "      <td>great movie: the product was in excellent cond...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>gjosepheat movie: the pjosephoduct was in exce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75122</th>\n",
              "      <td>disgusting: shakespeare may be a genius, but c...</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>disgusting: shakespeajosephe may be a genius, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76450</th>\n",
              "      <td>good: the product arrived as advertised and wa...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>good: the pjosephoduct ajosephjosephived as ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79602</th>\n",
              "      <td>just what i ordered!: this product was in the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>just what i ojosephdejosephed!: this pjosephod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79759</th>\n",
              "      <td>excellent scanner: this scanner is the sharpes...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>excellent scannejoseph: this scannejoseph is t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81072</th>\n",
              "      <td>excellent: this product was of high quality an...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>excellent: this pjosephoduct was of high quali...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ffd33af-5fbf-460f-9dbf-976bb1df703c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ffd33af-5fbf-460f-9dbf-976bb1df703c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ffd33af-5fbf-460f-9dbf-976bb1df703c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices_list = list(filtered_df.index)  # get a list of index for df_short_sentences, to keep indces from original df:\n",
        "jaccard_index_dict = {} # init Jaccard dict:"
      ],
      "metadata": {
        "id": "8QLcwDGXYaK3"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Create a list of sentence texts\n",
        "sentences = list(filtered_df.anon_txt.loc[indices_list_short])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "oyUg3WUqYaNr",
        "outputId": "4b811fd1-5713-46fb-9968-7d03a0e58d37"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1192\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5859\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5861\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[204, 332, 446, 669, 686, 725, 1232, 1436, 1811, 2185, 2253, 2255, 2297, 2309, 2396, 2478, 2601, 2658, 2760, 3102, 3153, 3175, 3375, 3507, 3661, 3685, 3827, 3887, 4158, 4371, 4786, 4788, 4796, 4800, 4829, 4869, 4895, 4959, 4994, 5374, 5415, 5466, 5544, 5642, 5721, 5914, 5936, 6086, 6135, 6151, 6155, 6550, 6602, 6610, 6639, 6716, 6760, 6830, 7114, 7158, 7307, 7325, 7443, 7463, 7654, 7657, 7699, 7735, 7946, 7951, 8160, 8243, 8592, 8604, 8687, 8794, 8873, 8887, 9050, 9194, 9252, 9255, 9315, 9350, 9478, 9535, 9541, 9599, 9631, 9941, 10281, 10415, 10416, 10472, 10500, 10522, 10533, 10543, 10574, 10975, 11169, 11263, 11347, 11789, 11835, 11860, 11950, 11959, 12042, 12118, 12134, 12351, 12541, 12559, 12615, 12833, 12872, 12898, 12909, 12915, 12956, 12976, 13060, 13087, 13223, 13254, 13265, 13387, 13441, 13451, 13574, 13732, 13802, 13809, 13852, 13888, 13894, 14022, 14048, 14290, 14630, 14664, 14704, 14871, 14878, 14928, 15001, 15161, 15283, 15327, 15539, 15631, 15706, 15886, 15938, 15960, 16038, 16107, 16220, 16292, 16411, 16425, 16431, 16469, 16675, 16873, 16958, 16988, 17097, 17107, 17271, 17520, 17527, 17535, 17626, 17833, 17980, 18092, 18098, 18224, 18327, 18424, 18445, 18690, 18742, 18773, 18827, 18853, 19402, 19434, 19585, 19601, 19637, 19784, 19822, 19911, 19918, 20099, 20143, 20268, 20421, 20546, 20579, 20615, 20737, 20743, 20744, 20784, 20790, 20817, 20932, 20991, 21017, 21020, 21049, 21051, 21139, 21207, 21283, 21326, 21525, 21570, 21912, 22063, 22..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices_list[1:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fngVSrYSiocG",
        "outputId": "8b86d976-5b4a-4f20-8451-33df1ab3a921"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6750, 6818, 7247]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Jaccard index for all pairs of sentences\n",
        "## more efficient code using ChatGPT:\n",
        "%%time\n",
        "jaccard_index_dict = {(indices_list_short[i],indices_list_short[j]): jaccard_index(sentences[i], sentences[j]) for i in range(len(sentences)) for j in range(i+1, len(sentences))}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-FgZimlYaQB",
        "outputId": "e1f81073-852d-43ba-986b-bdfaf3c0e101"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.7 s, sys: 43 ms, total: 3.74 s\n",
            "Wall time: 3.77 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the dictionary by its values in descending order\n",
        "sorted_dict = dict(sorted(jaccard_index_dict.items(), key=lambda item: item[1], reverse=True))"
      ],
      "metadata": {
        "id": "4MJijPb8ed-U"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7M49N1CikIG",
        "outputId": "83d549e4-0481-402b-bf47-b6d6d2d41ebe"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(23472, 23473): 0.8823529411764706,\n",
              " (33139, 76450): 0.4,\n",
              " (43561, 57499): 0.34615384615384615,\n",
              " (66810, 76450): 0.34615384615384615,\n",
              " (43561, 76450): 0.3333333333333333,\n",
              " (21174, 33789): 0.32,\n",
              " (49960, 76450): 0.32,\n",
              " (33050, 76450): 0.3103448275862069,\n",
              " (76450, 79602): 0.3103448275862069,\n",
              " (1806, 76450): 0.3076923076923077,\n",
              " (7936, 9069): 0.3076923076923077,\n",
              " (7936, 74700): 0.3076923076923077,\n",
              " (9069, 74700): 0.3076923076923077,\n",
              " (50794, 53483): 0.3076923076923077,\n",
              " (9069, 18389): 0.30434782608695654,\n",
              " (7936, 75122): 0.2962962962962963,\n",
              " (8621, 33050): 0.2962962962962963,\n",
              " (18123, 76450): 0.2962962962962963,\n",
              " (23383, 32071): 0.2962962962962963,\n",
              " (33050, 49960): 0.2962962962962963,\n",
              " (33139, 62478): 0.2962962962962963,\n",
              " (50794, 75066): 0.2962962962962963,\n",
              " (57499, 76450): 0.2962962962962963,\n",
              " (70446, 72226): 0.2962962962962963,\n",
              " (7247, 66810): 0.2857142857142857,\n",
              " (13317, 81072): 0.2857142857142857,\n",
              " (14069, 67509): 0.2857142857142857,\n",
              " (22101, 72226): 0.2857142857142857,\n",
              " (62478, 76450): 0.2857142857142857,\n",
              " (6818, 73103): 0.28,\n",
              " (9069, 14759): 0.28,\n",
              " (9069, 37353): 0.28,\n",
              " (44781, 57800): 0.28,\n",
              " (55147, 57075): 0.28,\n",
              " (57075, 69356): 0.28,\n",
              " (7247, 76450): 0.27586206896551724,\n",
              " (13127, 32539): 0.27586206896551724,\n",
              " (33050, 57499): 0.27586206896551724,\n",
              " (36483, 73997): 0.27586206896551724,\n",
              " (50794, 73218): 0.27586206896551724,\n",
              " (55147, 79602): 0.27586206896551724,\n",
              " (55293, 62478): 0.27586206896551724,\n",
              " (6750, 33139): 0.2692307692307692,\n",
              " (7936, 67089): 0.2692307692307692,\n",
              " (7936, 79759): 0.2692307692307692,\n",
              " (9069, 79759): 0.2692307692307692,\n",
              " (11713, 46767): 0.2692307692307692,\n",
              " (21137, 30285): 0.2692307692307692,\n",
              " (29417, 53483): 0.2692307692307692,\n",
              " (36611, 62554): 0.2692307692307692,\n",
              " (41466, 53483): 0.2692307692307692,\n",
              " (50794, 57075): 0.2692307692307692,\n",
              " (63077, 76450): 0.2692307692307692,\n",
              " (74700, 79759): 0.2692307692307692,\n",
              " (13127, 81072): 0.26666666666666666,\n",
              " (33050, 62478): 0.26666666666666666,\n",
              " (50304, 68306): 0.26666666666666666,\n",
              " (21174, 59270): 0.2608695652173913,\n",
              " (4788, 46986): 0.25925925925925924,\n",
              " (13317, 30320): 0.25925925925925924,\n",
              " (14069, 18445): 0.25925925925925924,\n",
              " (27209, 50304): 0.25925925925925924,\n",
              " (31613, 55147): 0.25925925925925924,\n",
              " (33789, 73103): 0.25925925925925924,\n",
              " (49960, 73218): 0.25925925925925924,\n",
              " (55274, 63077): 0.25925925925925924,\n",
              " (57499, 66810): 0.25925925925925924,\n",
              " (62478, 62554): 0.25925925925925924,\n",
              " (67089, 68136): 0.25925925925925924,\n",
              " (7657, 79602): 0.25806451612903225,\n",
              " (53826, 72095): 0.25806451612903225,\n",
              " (2396, 51076): 0.25,\n",
              " (6750, 12872): 0.25,\n",
              " (8621, 49960): 0.25,\n",
              " (10500, 34536): 0.25,\n",
              " (13317, 59593): 0.25,\n",
              " (20784, 50794): 0.25,\n",
              " (21174, 49960): 0.25,\n",
              " (25490, 69485): 0.25,\n",
              " (27223, 59593): 0.25,\n",
              " (30320, 39109): 0.25,\n",
              " (31613, 50794): 0.25,\n",
              " (31613, 58301): 0.25,\n",
              " (33050, 63077): 0.25,\n",
              " (34156, 43561): 0.25,\n",
              " (36611, 62478): 0.25,\n",
              " (43561, 54414): 0.25,\n",
              " (49960, 61179): 0.25,\n",
              " (49960, 79602): 0.25,\n",
              " (50794, 80521): 0.25,\n",
              " (59270, 73103): 0.25,\n",
              " (59593, 70610): 0.25,\n",
              " (66810, 81632): 0.25,\n",
              " (7936, 62160): 0.2413793103448276,\n",
              " (14069, 55063): 0.2413793103448276,\n",
              " (23383, 49244): 0.2413793103448276,\n",
              " (29421, 29465): 0.2413793103448276,\n",
              " (29421, 55147): 0.2413793103448276,\n",
              " (30320, 81072): 0.2413793103448276,\n",
              " (30998, 55063): 0.2413793103448276,\n",
              " (33789, 50794): 0.2413793103448276,\n",
              " (36611, 55293): 0.2413793103448276,\n",
              " (39109, 59593): 0.2413793103448276,\n",
              " (40724, 53552): 0.2413793103448276,\n",
              " (50794, 76450): 0.2413793103448276,\n",
              " (58024, 73294): 0.2413793103448276,\n",
              " (59593, 67509): 0.2413793103448276,\n",
              " (68136, 80293): 0.2413793103448276,\n",
              " (7158, 27638): 0.24,\n",
              " (9194, 57075): 0.24,\n",
              " (14759, 38316): 0.24,\n",
              " (21174, 73103): 0.24,\n",
              " (28873, 57075): 0.24,\n",
              " (31613, 59270): 0.24,\n",
              " (34156, 59270): 0.24,\n",
              " (40427, 75066): 0.24,\n",
              " (55147, 59270): 0.24,\n",
              " (59270, 80521): 0.24,\n",
              " (2478, 75122): 0.23333333333333334,\n",
              " (7247, 43561): 0.23333333333333334,\n",
              " (7325, 60686): 0.23333333333333334,\n",
              " (7657, 60686): 0.23333333333333334,\n",
              " (13127, 80293): 0.23333333333333334,\n",
              " (14069, 24233): 0.23333333333333334,\n",
              " (14069, 44242): 0.23333333333333334,\n",
              " (17520, 30815): 0.23333333333333334,\n",
              " (18092, 33050): 0.23333333333333334,\n",
              " (20737, 58301): 0.23333333333333334,\n",
              " (22151, 28290): 0.23333333333333334,\n",
              " (23529, 68252): 0.23333333333333334,\n",
              " (29421, 58301): 0.23333333333333334,\n",
              " (31613, 33050): 0.23333333333333334,\n",
              " (32071, 53079): 0.23333333333333334,\n",
              " (33050, 36611): 0.23333333333333334,\n",
              " (33050, 66810): 0.23333333333333334,\n",
              " (33139, 79602): 0.23333333333333334,\n",
              " (33789, 73218): 0.23333333333333334,\n",
              " (39109, 81072): 0.23333333333333334,\n",
              " (44242, 73294): 0.23333333333333334,\n",
              " (48360, 56026): 0.23333333333333334,\n",
              " (55293, 67509): 0.23333333333333334,\n",
              " (59000, 67881): 0.23333333333333334,\n",
              " (59593, 81072): 0.23333333333333334,\n",
              " (74751, 76450): 0.23333333333333334,\n",
              " (75066, 79602): 0.23333333333333334,\n",
              " (7936, 37353): 0.23076923076923078,\n",
              " (7936, 44781): 0.23076923076923078,\n",
              " (9350, 37353): 0.23076923076923078,\n",
              " (12118, 59270): 0.23076923076923078,\n",
              " (12833, 61179): 0.23076923076923078,\n",
              " (13317, 80666): 0.23076923076923078,\n",
              " (18092, 27587): 0.23076923076923078,\n",
              " (18092, 49960): 0.23076923076923078,\n",
              " (18445, 78089): 0.23076923076923078,\n",
              " (27587, 51548): 0.23076923076923078,\n",
              " (27587, 55147): 0.23076923076923078,\n",
              " (27587, 75066): 0.23076923076923078,\n",
              " (31613, 57075): 0.23076923076923078,\n",
              " (31613, 62738): 0.23076923076923078,\n",
              " (33789, 59270): 0.23076923076923078,\n",
              " (34156, 63077): 0.23076923076923078,\n",
              " (37353, 74700): 0.23076923076923078,\n",
              " (41356, 59270): 0.23076923076923078,\n",
              " (41498, 64438): 0.23076923076923078,\n",
              " (49960, 55147): 0.23076923076923078,\n",
              " (49960, 75066): 0.23076923076923078,\n",
              " (53483, 70333): 0.23076923076923078,\n",
              " (12915, 27223): 0.22727272727272727,\n",
              " (25646, 57075): 0.22727272727272727,\n",
              " (41146, 44781): 0.22727272727272727,\n",
              " (7247, 66537): 0.22580645161290322,\n",
              " (11713, 31379): 0.22580645161290322,\n",
              " (21137, 25271): 0.22580645161290322,\n",
              " (21137, 56026): 0.22580645161290322,\n",
              " (28400, 68229): 0.22580645161290322,\n",
              " (28532, 44794): 0.22580645161290322,\n",
              " (29873, 40724): 0.22580645161290322,\n",
              " (31379, 77233): 0.22580645161290322,\n",
              " (33050, 43561): 0.22580645161290322,\n",
              " (33050, 50794): 0.22580645161290322,\n",
              " (39330, 56026): 0.22580645161290322,\n",
              " (50794, 79602): 0.22580645161290322,\n",
              " (63729, 65862): 0.22580645161290322,\n",
              " (72226, 79602): 0.22580645161290322,\n",
              " (1806, 18123): 0.2222222222222222,\n",
              " (1806, 33139): 0.2222222222222222,\n",
              " (7936, 78456): 0.2222222222222222,\n",
              " (7946, 11789): 0.2222222222222222,\n",
              " (7946, 46848): 0.2222222222222222,\n",
              " (8621, 33789): 0.2222222222222222,\n",
              " (9194, 25136): 0.2222222222222222,\n",
              " (9194, 31613): 0.2222222222222222,\n",
              " (9194, 34156): 0.2222222222222222,\n",
              " (9194, 34844): 0.2222222222222222,\n",
              " (9194, 75066): 0.2222222222222222,\n",
              " (9194, 80521): 0.2222222222222222,\n",
              " (10543, 52624): 0.2222222222222222,\n",
              " (11347, 30320): 0.2222222222222222,\n",
              " (18445, 32071): 0.2222222222222222,\n",
              " (18445, 38056): 0.2222222222222222,\n",
              " (19585, 37659): 0.2222222222222222,\n",
              " (20143, 63746): 0.2222222222222222,\n",
              " (20743, 76450): 0.2222222222222222,\n",
              " (20817, 67089): 0.2222222222222222,\n",
              " (21137, 25282): 0.2222222222222222,\n",
              " (21137, 25632): 0.2222222222222222,\n",
              " (21174, 76450): 0.2222222222222222,\n",
              " (25282, 56941): 0.2222222222222222,\n",
              " (25282, 73294): 0.2222222222222222,\n",
              " (27587, 50794): 0.2222222222222222,\n",
              " (27587, 76450): 0.2222222222222222,\n",
              " (28873, 69356): 0.2222222222222222,\n",
              " (31385, 69741): 0.2222222222222222,\n",
              " (31613, 53483): 0.2222222222222222,\n",
              " (31916, 46767): 0.2222222222222222,\n",
              " (32071, 78089): 0.2222222222222222,\n",
              " (33789, 37353): 0.2222222222222222,\n",
              " (33789, 49960): 0.2222222222222222,\n",
              " (34156, 82156): 0.2222222222222222,\n",
              " (43561, 63077): 0.2222222222222222,\n",
              " (44781, 75122): 0.2222222222222222,\n",
              " (44878, 57499): 0.2222222222222222,\n",
              " (49960, 50794): 0.2222222222222222,\n",
              " (50794, 63077): 0.2222222222222222,\n",
              " (55489, 58419): 0.2222222222222222,\n",
              " (69356, 73103): 0.2222222222222222,\n",
              " (70357, 82156): 0.2222222222222222,\n",
              " (80521, 82156): 0.2222222222222222,\n",
              " (6760, 7325): 0.21875,\n",
              " (9535, 19911): 0.21875,\n",
              " (13127, 40724): 0.21875,\n",
              " (13127, 56026): 0.21875,\n",
              " (20790, 31379): 0.21875,\n",
              " (25271, 30992): 0.21875,\n",
              " (25490, 31379): 0.21875,\n",
              " (28290, 44794): 0.21875,\n",
              " (33050, 73218): 0.21875,\n",
              " (73218, 79602): 0.21875,\n",
              " (14759, 18389): 0.21739130434782608,\n",
              " (446, 47908): 0.21428571428571427,\n",
              " (1806, 62478): 0.21428571428571427,\n",
              " (7936, 9350): 0.21428571428571427,\n",
              " (7936, 36611): 0.21428571428571427,\n",
              " (7936, 51762): 0.21428571428571427,\n",
              " (8621, 73218): 0.21428571428571427,\n",
              " (9069, 9350): 0.21428571428571427,\n",
              " (9350, 74700): 0.21428571428571427,\n",
              " (10533, 53483): 0.21428571428571427,\n",
              " (11347, 39109): 0.21428571428571427,\n",
              " (12833, 55147): 0.21428571428571427,\n",
              " (13127, 37353): 0.21428571428571427,\n",
              " (13317, 22151): 0.21428571428571427,\n",
              " (13317, 32071): 0.21428571428571427,\n",
              " (13317, 74429): 0.21428571428571427,\n",
              " (13317, 75066): 0.21428571428571427,\n",
              " (14022, 14069): 0.21428571428571427,\n",
              " (14022, 19637): 0.21428571428571427,\n",
              " (14759, 24233): 0.21428571428571427,\n",
              " (18092, 66810): 0.21428571428571427,\n",
              " (18445, 67509): 0.21428571428571427,\n",
              " (18445, 73294): 0.21428571428571427,\n",
              " (20784, 31613): 0.21428571428571427,\n",
              " (20784, 34156): 0.21428571428571427,\n",
              " (20784, 36611): 0.21428571428571427,\n",
              " (20784, 75066): 0.21428571428571427,\n",
              " (21174, 73218): 0.21428571428571427,\n",
              " (22151, 80186): 0.21428571428571427,\n",
              " (25136, 34156): 0.21428571428571427,\n",
              " (25136, 70610): 0.21428571428571427,\n",
              " (27288, 30320): 0.21428571428571427,\n",
              " (27288, 33139): 0.21428571428571427,\n",
              " (27288, 75066): 0.21428571428571427,\n",
              " (27587, 73218): 0.21428571428571427,\n",
              " (28856, 52066): 0.21428571428571427,\n",
              " (28873, 50794): 0.21428571428571427,\n",
              " (31613, 34156): 0.21428571428571427,\n",
              " (31613, 36611): 0.21428571428571427,\n",
              " (31613, 80521): 0.21428571428571427,\n",
              " (33050, 59270): 0.21428571428571427,\n",
              " (33789, 53483): 0.21428571428571427,\n",
              " (34156, 36611): 0.21428571428571427,\n",
              " (34156, 57499): 0.21428571428571427,\n",
              " (34156, 75066): 0.21428571428571427,\n",
              " (34156, 80521): 0.21428571428571427,\n",
              " (36611, 49724): 0.21428571428571427,\n",
              " (36611, 70610): 0.21428571428571427,\n",
              " (37353, 62160): 0.21428571428571427,\n",
              " (37659, 70809): 0.21428571428571427,\n",
              " (41478, 55063): 0.21428571428571427,\n",
              " (42668, 53483): 0.21428571428571427,\n",
              " (44878, 76450): 0.21428571428571427,\n",
              " (49164, 49244): 0.21428571428571427,\n",
              " (50304, 78089): 0.21428571428571427,\n",
              " (50794, 58111): 0.21428571428571427,\n",
              " (52363, 64987): 0.21428571428571427,\n",
              " (52363, 73997): 0.21428571428571427,\n",
              " (53483, 56017): 0.21428571428571427,\n",
              " (53483, 76450): 0.21428571428571427,\n",
              " (55063, 82156): 0.21428571428571427,\n",
              " (55147, 75066): 0.21428571428571427,\n",
              " (55274, 57075): 0.21428571428571427,\n",
              " (57292, 67089): 0.21428571428571427,\n",
              " (59379, 73294): 0.21428571428571427,\n",
              " (61560, 75542): 0.21428571428571427,\n",
              " (67089, 75122): 0.21428571428571427,\n",
              " (75122, 79759): 0.21428571428571427,\n",
              " (80666, 81072): 0.21428571428571427,\n",
              " (6639, 15938): 0.21212121212121213,\n",
              " (30815, 40893): 0.21212121212121213,\n",
              " (33050, 79602): 0.21212121212121213,\n",
              " (40724, 56026): 0.21212121212121213,\n",
              " (18389, 38316): 0.20833333333333334,\n",
              " (25646, 46986): 0.20833333333333334,\n",
              " (25646, 63746): 0.20833333333333334,\n",
              " (27223, 36611): 0.20833333333333334,\n",
              " (27223, 70610): 0.20833333333333334,\n",
              " (41146, 53788): 0.20833333333333334,\n",
              " (56522, 56538): 0.20833333333333334,\n",
              " (57075, 59270): 0.20833333333333334,\n",
              " (59270, 63077): 0.20833333333333334,\n",
              " (446, 16038): 0.20689655172413793,\n",
              " (1806, 28287): 0.20689655172413793,\n",
              " (1806, 55293): 0.20689655172413793,\n",
              " (1811, 66981): 0.20689655172413793,\n",
              " (2478, 67089): 0.20689655172413793,\n",
              " (2478, 79759): 0.20689655172413793,\n",
              " (6750, 7247): 0.20689655172413793,\n",
              " (7158, 82490): 0.20689655172413793,\n",
              " (7325, 29178): 0.20689655172413793,\n",
              " (7936, 68776): 0.20689655172413793,\n",
              " (7946, 31379): 0.20689655172413793,\n",
              " (7946, 55293): 0.20689655172413793,\n",
              " (9069, 70337): 0.20689655172413793,\n",
              " (9069, 75122): 0.20689655172413793,\n",
              " (9194, 78684): 0.20689655172413793,\n",
              " (9350, 32539): 0.20689655172413793,\n",
              " (11347, 38280): 0.20689655172413793,\n",
              " (12541, 17520): 0.20689655172413793,\n",
              " (13317, 21137): 0.20689655172413793,\n",
              " (13317, 23383): 0.20689655172413793,\n",
              " (13317, 30998): 0.20689655172413793,\n",
              " (13317, 39109): 0.20689655172413793,\n",
              " (14069, 19601): 0.20689655172413793,\n",
              " (16107, 32539): 0.20689655172413793,\n",
              " (16675, 57499): 0.20689655172413793,\n",
              " (18092, 43561): 0.20689655172413793,\n",
              " (18092, 76450): 0.20689655172413793,\n",
              " (18424, 72226): 0.20689655172413793,\n",
              " (18445, 24233): 0.20689655172413793,\n",
              " (18445, 44242): 0.20689655172413793,\n",
              " (18690, 34156): 0.20689655172413793,\n",
              " (18690, 70610): 0.20689655172413793,\n",
              " (19585, 44794): 0.20689655172413793,\n",
              " (19601, 55063): 0.20689655172413793,\n",
              " (19601, 68776): 0.20689655172413793,\n",
              " (19601, 73294): 0.20689655172413793,\n",
              " (20784, 64382): 0.20689655172413793,\n",
              " (21137, 73558): 0.20689655172413793,\n",
              " (21174, 33050): 0.20689655172413793,\n",
              " (22101, 70446): 0.20689655172413793,\n",
              " (22853, 31154): 0.20689655172413793,\n",
              " (24195, 34329): 0.20689655172413793,\n",
              " (25136, 59593): 0.20689655172413793,\n",
              " (26592, 69741): 0.20689655172413793,\n",
              " (27137, 57499): 0.20689655172413793,\n",
              " (27288, 62478): 0.20689655172413793,\n",
              " (27288, 76450): 0.20689655172413793,\n",
              " (27347, 38056): 0.20689655172413793,\n",
              " (27587, 79602): 0.20689655172413793,\n",
              " (29417, 42668): 0.20689655172413793,\n",
              " (29955, 67089): 0.20689655172413793,\n",
              " (30320, 59593): 0.20689655172413793,\n",
              " (31379, 78456): 0.20689655172413793,\n",
              " (31613, 62478): 0.20689655172413793,\n",
              " (31613, 76450): 0.20689655172413793,\n",
              " (32071, 42668): 0.20689655172413793,\n",
              " (32071, 49244): 0.20689655172413793,\n",
              " (32071, 59593): 0.20689655172413793,\n",
              " (33139, 43561): 0.20689655172413793,\n",
              " (33360, 47902): 0.20689655172413793,\n",
              " (33789, 69356): 0.20689655172413793,\n",
              " (34156, 50794): 0.20689655172413793,\n",
              " (34156, 58301): 0.20689655172413793,\n",
              " (34156, 76450): 0.20689655172413793,\n",
              " (34156, 76579): 0.20689655172413793,\n",
              " (34284, 56327): 0.20689655172413793,\n",
              " (34844, 62478): 0.20689655172413793,\n",
              " (34844, 76450): 0.20689655172413793,\n",
              " (36611, 42668): 0.20689655172413793,\n",
              " (36611, 45736): 0.20689655172413793,\n",
              " (36611, 50794): 0.20689655172413793,\n",
              " (36611, 58024): 0.20689655172413793,\n",
              " (36611, 58301): 0.20689655172413793,\n",
              " (36611, 68776): 0.20689655172413793,\n",
              " (36611, 76450): 0.20689655172413793,\n",
              " (38056, 56941): 0.20689655172413793,\n",
              " (38316, 75515): 0.20689655172413793,\n",
              " (38913, 70560): 0.20689655172413793,\n",
              " (39330, 48360): 0.20689655172413793,\n",
              " (39694, 50304): 0.20689655172413793,\n",
              " (40893, 77920): 0.20689655172413793,\n",
              " (41356, 55147): 0.20689655172413793,\n",
              " (41478, 55293): 0.20689655172413793,\n",
              " (43561, 66810): 0.20689655172413793,\n",
              " (44290, 51244): 0.20689655172413793,\n",
              " (44290, 63796): 0.20689655172413793,\n",
              " (44588, 81942): 0.20689655172413793,\n",
              " (45736, 70809): 0.20689655172413793,\n",
              " (48360, 72526): 0.20689655172413793,\n",
              " (50304, 51428): 0.20689655172413793,\n",
              " (50794, 55147): 0.20689655172413793,\n",
              " (50794, 66810): 0.20689655172413793,\n",
              " (50794, 69356): 0.20689655172413793,\n",
              " (50794, 70610): 0.20689655172413793,\n",
              " (51428, 75542): 0.20689655172413793,\n",
              " (51762, 69576): 0.20689655172413793,\n",
              " (53483, 73218): 0.20689655172413793,\n",
              " (53483, 74751): 0.20689655172413793,\n",
              " (53826, 67089): 0.20689655172413793,\n",
              " (54414, 76450): 0.20689655172413793,\n",
              " (55147, 58301): 0.20689655172413793,\n",
              " (55147, 76450): 0.20689655172413793,\n",
              " (55293, 62554): 0.20689655172413793,\n",
              " (56327, 74700): 0.20689655172413793,\n",
              " (57075, 79602): 0.20689655172413793,\n",
              " (59000, 59342): 0.20689655172413793,\n",
              " (60230, 63746): 0.20689655172413793,\n",
              " (61765, 76450): 0.20689655172413793,\n",
              " (61789, 72526): 0.20689655172413793,\n",
              " (62160, 67089): 0.20689655172413793,\n",
              " (62176, 68776): 0.20689655172413793,\n",
              " (62478, 69741): 0.20689655172413793,\n",
              " (70610, 76450): 0.20689655172413793,\n",
              " (71959, 79602): 0.20689655172413793,\n",
              " (72014, 82156): 0.20689655172413793,\n",
              " (73103, 73218): 0.20689655172413793,\n",
              " (74700, 75122): 0.20689655172413793,\n",
              " (75066, 76450): 0.20689655172413793,\n",
              " (76450, 80186): 0.20689655172413793,\n",
              " (669, 21570): 0.2,\n",
              " (2478, 7936): 0.2,\n",
              " (2478, 9069): 0.2,\n",
              " (2478, 20817): 0.2,\n",
              " (2478, 74700): 0.2,\n",
              " (4788, 53361): 0.2,\n",
              " (6155, 66537): 0.2,\n",
              " (6760, 82156): 0.2,\n",
              " (7114, 44781): 0.2,\n",
              " (7158, 20615): 0.2,\n",
              " (7158, 44723): 0.2,\n",
              " (7247, 18123): 0.2,\n",
              " (7247, 33139): 0.2,\n",
              " (7247, 34156): 0.2,\n",
              " (7247, 57499): 0.2,\n",
              " (7247, 66571): 0.2,\n",
              " (7463, 42806): 0.2,\n",
              " (7657, 37659): 0.2,\n",
              " (7936, 13127): 0.2,\n",
              " (7936, 18389): 0.2,\n",
              " (7936, 29955): 0.2,\n",
              " (7936, 55293): 0.2,\n",
              " (8621, 21174): 0.2,\n",
              " (8621, 80666): 0.2,\n",
              " (8687, 58244): 0.2,\n",
              " (9069, 13127): 0.2,\n",
              " (9069, 29955): 0.2,\n",
              " (9069, 62160): 0.2,\n",
              " (9194, 28290): 0.2,\n",
              " (9350, 13127): 0.2,\n",
              " (10543, 53826): 0.2,\n",
              " (10543, 73077): 0.2,\n",
              " (11713, 36022): 0.2,\n",
              " (12042, 22101): 0.2,\n",
              " (12118, 50794): 0.2,\n",
              " (12872, 33139): 0.2,\n",
              " (13127, 30320): 0.2,\n",
              " (13127, 33360): 0.2,\n",
              " (13127, 48360): 0.2,\n",
              " (13127, 74700): 0.2,\n",
              " (13127, 75066): 0.2,\n",
              " (13317, 46030): 0.2,\n",
              " (13317, 60619): 0.2,\n",
              " (13574, 31379): 0.2,\n",
              " (13732, 23608): 0.2,\n",
              " (14069, 19637): 0.2,\n",
              " (14069, 21137): 0.2,\n",
              " (14069, 68776): 0.2,\n",
              " (14069, 73294): 0.2,\n",
              " (14069, 75062): 0.2,\n",
              " (14759, 44781): 0.2,\n",
              " (15283, 68776): 0.2,\n",
              " (16469, 32071): 0.2,\n",
              " (17097, 34844): 0.2,\n",
              " (17520, 68999): 0.2,\n",
              " (18389, 18424): 0.2,\n",
              " (18389, 74700): 0.2,\n",
              " (19434, 59342): 0.2,\n",
              " (19585, 28290): 0.2,\n",
              " (20784, 55274): 0.2,\n",
              " (20817, 29955): 0.2,\n",
              " (20817, 53826): 0.2,\n",
              " (20932, 23529): 0.2,\n",
              " (20932, 23652): 0.2,\n",
              " (21137, 42873): 0.2,\n",
              " (21137, 56941): 0.2,\n",
              " (21137, 72226): 0.2,\n",
              " (21137, 73294): 0.2,\n",
              " (21174, 63077): 0.2,\n",
              " (22338, 59270): 0.2,\n",
              " (23383, 42668): 0.2,\n",
              " (23413, 41604): 0.2,\n",
              " (23413, 75542): 0.2,\n",
              " (23647, 76080): 0.2,\n",
              " (24218, 80666): 0.2,\n",
              " (25271, 66981): 0.2,\n",
              " (25646, 76450): 0.2,\n",
              " (27223, 42668): 0.2,\n",
              " (27288, 81072): 0.2,\n",
              " (27347, 56941): 0.2,\n",
              " (27347, 58024): 0.2,\n",
              " (27587, 49960): 0.2,\n",
              " (27587, 57075): 0.2,\n",
              " (27587, 67144): 0.2,\n",
              " (28290, 62554): 0.2,\n",
              " (28856, 45736): 0.2,\n",
              " (28873, 59270): 0.2,\n",
              " (29417, 48535): 0.2,\n",
              " (29417, 55293): 0.2,\n",
              " (29421, 31613): 0.2,\n",
              " (29421, 34156): 0.2,\n",
              " (29421, 75066): 0.2,\n",
              " (29955, 74700): 0.2,\n",
              " (29955, 77619): 0.2,\n",
              " (30815, 50874): 0.2,\n",
              " (31154, 59593): 0.2,\n",
              " (31154, 68776): 0.2,\n",
              " (31228, 31379): 0.2,\n",
              " (31379, 41262): 0.2,\n",
              " (31379, 46848): 0.2,\n",
              " (31613, 72014): 0.2,\n",
              " (31613, 76414): 0.2,\n",
              " (32071, 37042): 0.2,\n",
              " (32071, 46030): 0.2,\n",
              " (32539, 80293): 0.2,\n",
              " (33050, 62554): 0.2,\n",
              " (33139, 78305): 0.2,\n",
              " (33139, 81072): 0.2,\n",
              " (33789, 76450): 0.2,\n",
              " (34156, 55274): 0.2,\n",
              " (34156, 66537): 0.2,\n",
              " (34329, 55293): 0.2,\n",
              " (34844, 72014): 0.2,\n",
              " (36611, 69003): 0.2,\n",
              " (37353, 44781): 0.2,\n",
              " (37383, 68976): 0.2,\n",
              " (37659, 44794): 0.2,\n",
              " (39330, 45399): 0.2,\n",
              " (39330, 55063): 0.2,\n",
              " (40327, 69741): 0.2,\n",
              " (40728, 53826): 0.2,\n",
              " (41146, 62231): 0.2,\n",
              " (41207, 41262): 0.2,\n",
              " (42668, 49244): 0.2,\n",
              " (42668, 50794): 0.2,\n",
              " (42873, 56941): 0.2,\n",
              " (44242, 44588): 0.2,\n",
              " (44242, 48791): 0.2,\n",
              " (45399, 55063): 0.2,\n",
              " (45661, 46848): 0.2,\n",
              " (46030, 74429): 0.2,\n",
              " (46426, 53826): 0.2,\n",
              " (46762, 68229): 0.2,\n",
              " (49244, 66015): 0.2,\n",
              " (49244, 74126): 0.2,\n",
              " (49724, 66537): 0.2,\n",
              " (49960, 63077): 0.2,\n",
              " (50304, 75542): 0.2,\n",
              " (50794, 69347): 0.2,\n",
              " (51632, 77988): 0.2,\n",
              " (52716, 78438): 0.2,\n",
              " (53483, 79602): 0.2,\n",
              " (54436, 76422): 0.2,\n",
              " (54527, 66015): 0.2,\n",
              " (55063, 58024): 0.2,\n",
              " (55147, 73218): 0.2,\n",
              " (55274, 69356): 0.2,\n",
              " (56941, 73294): 0.2,\n",
              " (57075, 63077): 0.2,\n",
              " (58024, 67509): 0.2,\n",
              " (58024, 74126): 0.2,\n",
              " (58304, 63729): 0.2,\n",
              " (59270, 82156): 0.2,\n",
              " (59593, 62478): 0.2,\n",
              " (59593, 69347): 0.2,\n",
              " (59593, 76450): 0.2,\n",
              " (60230, 79789): 0.2,\n",
              " (60686, 63359): 0.2,\n",
              " (62160, 74700): 0.2,\n",
              " (63729, 68776): 0.2,\n",
              " (63770, 69748): 0.2,\n",
              " (66537, 75066): 0.2,\n",
              " (68776, 73294): 0.2,\n",
              " (69003, 70610): 0.2,\n",
              " (69356, 73218): 0.2,\n",
              " (70333, 79602): 0.2,\n",
              " (70337, 74126): 0.2,\n",
              " (70410, 77233): 0.2,\n",
              " (70410, 78684): 0.2,\n",
              " (70560, 80103): 0.2,\n",
              " (72047, 81452): 0.2,\n",
              " (73218, 75066): 0.2,\n",
              " (75066, 81072): 0.2,\n",
              " (75122, 80293): 0.2,\n",
              " (204, 59342): 0.1935483870967742,\n",
              " (2478, 32539): 0.1935483870967742,\n",
              " (2478, 57292): 0.1935483870967742,\n",
              " (2478, 80293): 0.1935483870967742,\n",
              " (4895, 13317): 0.1935483870967742,\n",
              " (5544, 21525): 0.1935483870967742,\n",
              " (5936, 7657): 0.1935483870967742,\n",
              " (6602, 67262): 0.1935483870967742,\n",
              " (6602, 70560): 0.1935483870967742,\n",
              " (6760, 31613): 0.1935483870967742,\n",
              " (7247, 50794): 0.1935483870967742,\n",
              " (7247, 81632): 0.1935483870967742,\n",
              " (7325, 21525): 0.1935483870967742,\n",
              " (7325, 39109): 0.1935483870967742,\n",
              " (7325, 59593): 0.1935483870967742,\n",
              " (7325, 72526): 0.1935483870967742,\n",
              " (7936, 15938): 0.1935483870967742,\n",
              " (7936, 28290): 0.1935483870967742,\n",
              " (7936, 40724): 0.1935483870967742,\n",
              " (8687, 28287): 0.1935483870967742,\n",
              " (8794, 42668): 0.1935483870967742,\n",
              " (8794, 70560): 0.1935483870967742,\n",
              " (8794, 75062): 0.1935483870967742,\n",
              " (9631, 41207): 0.1935483870967742,\n",
              " (10975, 59000): 0.1935483870967742,\n",
              " (12872, 43561): 0.1935483870967742,\n",
              " (13127, 14069): 0.1935483870967742,\n",
              " (13317, 28290): 0.1935483870967742,\n",
              " (13894, 58304): 0.1935483870967742,\n",
              " (13894, 63729): 0.1935483870967742,\n",
              " (15001, 50304): 0.1935483870967742,\n",
              " (15938, 41262): 0.1935483870967742,\n",
              " (15938, 74700): 0.1935483870967742,\n",
              " (16469, 23383): 0.1935483870967742,\n",
              " (16675, 74751): 0.1935483870967742,\n",
              " (16675, 78292): 0.1935483870967742,\n",
              " (19601, 32092): 0.1935483870967742,\n",
              " (20744, 73218): 0.1935483870967742,\n",
              " (20784, 33050): 0.1935483870967742,\n",
              " (21017, 51076): 0.1935483870967742,\n",
              " (21137, 44242): 0.1935483870967742,\n",
              " (21525, 28532): 0.1935483870967742,\n",
              " (24233, 55063): 0.1935483870967742,\n",
              " (24233, 68776): 0.1935483870967742,\n",
              " (24601, 27347): 0.1935483870967742,\n",
              " (27288, 68229): 0.1935483870967742,\n",
              " (27288, 79602): 0.1935483870967742,\n",
              " (28290, 30320): 0.1935483870967742,\n",
              " (28290, 36611): 0.1935483870967742,\n",
              " (28290, 37659): 0.1935483870967742,\n",
              " (28290, 51762): 0.1935483870967742,\n",
              " (28290, 69741): 0.1935483870967742,\n",
              " (28290, 75066): 0.1935483870967742,\n",
              " (29421, 50794): 0.1935483870967742,\n",
              " (29955, 32539): 0.1935483870967742,\n",
              " (30815, 31228): 0.1935483870967742,\n",
              " (31228, 40893): 0.1935483870967742,\n",
              " (31379, 70741): 0.1935483870967742,\n",
              " (31916, 56539): 0.1935483870967742,\n",
              " (33050, 47138): 0.1935483870967742,\n",
              " (33050, 55147): 0.1935483870967742,\n",
              " (33050, 80186): 0.1935483870967742,\n",
              " (33050, 80521): 0.1935483870967742,\n",
              " (33789, 50479): 0.1935483870967742,\n",
              " (36022, 53079): 0.1935483870967742,\n",
              " (36611, 79602): 0.1935483870967742,\n",
              " (36611, 82992): 0.1935483870967742,\n",
              " (37872, 41604): 0.1935483870967742,\n",
              " (39608, 45399): 0.1935483870967742,\n",
              " (40724, 41510): 0.1935483870967742,\n",
              " (40724, 48360): 0.1935483870967742,\n",
              " (41207, 56776): 0.1935483870967742,\n",
              " (41207, 75542): 0.1935483870967742,\n",
              " (44242, 68776): 0.1935483870967742,\n",
              " (44679, 54527): 0.1935483870967742,\n",
              " (44939, 75066): 0.1935483870967742,\n",
              " (46631, 75515): 0.1935483870967742,\n",
              " (48535, 56097): 0.1935483870967742,\n",
              " (48535, 59000): 0.1935483870967742,\n",
              " (48976, 59593): 0.1935483870967742,\n",
              " (49098, 74700): 0.1935483870967742,\n",
              " (49372, 50235): 0.1935483870967742,\n",
              " (50794, 55274): 0.1935483870967742,\n",
              " (50794, 57400): 0.1935483870967742,\n",
              " (50794, 66537): 0.1935483870967742,\n",
              " (50794, 74751): 0.1935483870967742,\n",
              " (50794, 78305): 0.1935483870967742,\n",
              " (51428, 68306): 0.1935483870967742,\n",
              " (51886, 68136): 0.1935483870967742,\n",
              " (52716, 59000): 0.1935483870967742,\n",
              " (53826, 57292): 0.1935483870967742,\n",
              " (53826, 75542): 0.1935483870967742,\n",
              " (55063, 55293): 0.1935483870967742,\n",
              " (55274, 76450): 0.1935483870967742,\n",
              " (55293, 59593): 0.1935483870967742,\n",
              " (56539, 66537): 0.1935483870967742,\n",
              " (57292, 62160): 0.1935483870967742,\n",
              " (57466, 59642): 0.1935483870967742,\n",
              " (62160, 75122): 0.1935483870967742,\n",
              " (62478, 72014): 0.1935483870967742,\n",
              " (62478, 76414): 0.1935483870967742,\n",
              " (62478, 81072): 0.1935483870967742,\n",
              " (63166, 67909): 0.1935483870967742,\n",
              " (63729, 65684): 0.1935483870967742,\n",
              " (63796, 70374): 0.1935483870967742,\n",
              " (65684, 74126): 0.1935483870967742,\n",
              " (66322, 82490): 0.1935483870967742,\n",
              " (67509, 81072): 0.1935483870967742,\n",
              " (68229, 75066): 0.1935483870967742,\n",
              " (68999, 77552): 0.1935483870967742,\n",
              " (70560, 75515): 0.1935483870967742,\n",
              " (72843, 82512): 0.1935483870967742,\n",
              " (73218, 76450): 0.1935483870967742,\n",
              " (76450, 78305): 0.1935483870967742,\n",
              " (76450, 81072): 0.1935483870967742,\n",
              " (79602, 80186): 0.1935483870967742,\n",
              " (1806, 20743): 0.19230769230769232,\n",
              " (7114, 77614): 0.19230769230769232,\n",
              " (7657, 27223): 0.19230769230769232,\n",
              " (8621, 43592): 0.19230769230769232,\n",
              " (9194, 27587): 0.19230769230769232,\n",
              " (9350, 27687): 0.19230769230769232,\n",
              " (9478, 27223): 0.19230769230769232,\n",
              " (11347, 24218): 0.19230769230769232,\n",
              " (11347, 80666): 0.19230769230769232,\n",
              " (12134, 25632): 0.19230769230769232,\n",
              " (18389, 59000): 0.19230769230769232,\n",
              " (18389, 70337): 0.19230769230769232,\n",
              " (18445, 25282): 0.19230769230769232,\n",
              " (18445, 30285): 0.19230769230769232,\n",
              " (18445, 44781): 0.19230769230769232,\n",
              " (21137, 22301): 0.19230769230769232,\n",
              " (21174, 28873): 0.19230769230769232,\n",
              " (21174, 44878): 0.19230769230769232,\n",
              " (22301, 72226): 0.19230769230769232,\n",
              " (24218, 78089): 0.19230769230769232,\n",
              " (25632, 52066): 0.19230769230769232,\n",
              " (25632, 79759): 0.19230769230769232,\n",
              " (27223, 38280): 0.19230769230769232,\n",
              " (27223, 48976): 0.19230769230769232,\n",
              " (27223, 69003): 0.19230769230769232,\n",
              " (27587, 28873): 0.19230769230769232,\n",
              " (27587, 44878): 0.19230769230769232,\n",
              " (27638, 40728): 0.19230769230769232,\n",
              " (28365, 51775): 0.19230769230769232,\n",
              " (28873, 63077): 0.19230769230769232,\n",
              " (30285, 59379): 0.19230769230769232,\n",
              " (34156, 38530): 0.19230769230769232,\n",
              " (37353, 79759): 0.19230769230769232,\n",
              " (44781, 58685): 0.19230769230769232,\n",
              " (44781, 72441): 0.19230769230769232,\n",
              " (44878, 49960): 0.19230769230769232,\n",
              " (44878, 63077): 0.19230769230769232,\n",
              " (46767, 57379): 0.19230769230769232,\n",
              " (50874, 71959): 0.19230769230769232,\n",
              " (54545, 55489): 0.19230769230769232,\n",
              " (56784, 71959): 0.19230769230769232,\n",
              " (57075, 73103): 0.19230769230769232,\n",
              " (57499, 59270): 0.19230769230769232,\n",
              " (58685, 64399): 0.19230769230769232,\n",
              " (70333, 71959): 0.19230769230769232,\n",
              " (1811, 6151): 0.1875,\n",
              " (1811, 30992): 0.1875,\n",
              " (1811, 41207): 0.1875,\n",
              " (1811, 75515): 0.1875,\n",
              " (2253, 49098): 0.1875,\n",
              " (2478, 29955): 0.1875,\n",
              " (2478, 53826): 0.1875,\n",
              " (4895, 29873): 0.1875,\n",
              " (4895, 46600): 0.1875,\n",
              " (5936, 79602): 0.1875,\n",
              " (6151, 8794): 0.1875,\n",
              " (6639, 21525): 0.1875,\n",
              " (6760, 55063): 0.1875,\n",
              " (6760, 62478): 0.1875,\n",
              " (7325, 7657): 0.1875,\n",
              " (7325, 55293): 0.1875,\n",
              " (7657, 9478): 0.1875,\n",
              " (7657, 17097): 0.1875,\n",
              " (7657, 76414): 0.1875,\n",
              " (8687, 49098): 0.1875,\n",
              " (9478, 60619): 0.1875,\n",
              " (11713, 31916): 0.1875,\n",
              " (11713, 75515): 0.1875,\n",
              " (12976, 56026): 0.1875,\n",
              " (13127, 24233): 0.1875,\n",
              " (13127, 29955): 0.1875,\n",
              " (13127, 68252): 0.1875,\n",
              " (13809, 75542): 0.1875,\n",
              " (14069, 32092): 0.1875,\n",
              " (14069, 40724): 0.1875,\n",
              " (14704, 65862): 0.1875,\n",
              " (15631, 35930): 0.1875,\n",
              " (15938, 21525): 0.1875,\n",
              " (15938, 31154): 0.1875,\n",
              " (15938, 55063): 0.1875,\n",
              " (15938, 68776): 0.1875,\n",
              " (15938, 75122): 0.1875,\n",
              " (15938, 75542): 0.1875,\n",
              " (16038, 25271): 0.1875,\n",
              " (17097, 44794): 0.1875,\n",
              " (19784, 49372): 0.1875,\n",
              " (20991, 81895): 0.1875,\n",
              " (21137, 40724): 0.1875,\n",
              " (22101, 80961): 0.1875,\n",
              " (24233, 44242): 0.1875,\n",
              " (25271, 56941): 0.1875,\n",
              " (25490, 47902): 0.1875,\n",
              " (25490, 52375): 0.1875,\n",
              " (25490, 55063): 0.1875,\n",
              " (28290, 62478): 0.1875,\n",
              " (28290, 63359): 0.1875,\n",
              " (28290, 69748): 0.1875,\n",
              " (29873, 79602): 0.1875,\n",
              " (29955, 45661): 0.1875,\n",
              " (30992, 31916): 0.1875,\n",
              " (31379, 45661): 0.1875,\n",
              " (31379, 78832): 0.1875,\n",
              " (31916, 44723): 0.1875,\n",
              " (31916, 77049): 0.1875,\n",
              " (33050, 33789): 0.1875,\n",
              " (34315, 58419): 0.1875,\n",
              " (40724, 70560): 0.1875,\n",
              " (40724, 72047): 0.1875,\n",
              " (40724, 80103): 0.1875,\n",
              " (40850, 44794): 0.1875,\n",
              " (41207, 75515): 0.1875,\n",
              " (41604, 63677): 0.1875,\n",
              " (44939, 50794): 0.1875,\n",
              " (50235, 52051): 0.1875,\n",
              " (51632, 79602): 0.1875,\n",
              " (51873, 75515): 0.1875,\n",
              " (55293, 81072): 0.1875,\n",
              " (56941, 82992): 0.1875,\n",
              " (57292, 72095): 0.1875,\n",
              " (58419, 70513): 0.1875,\n",
              " (59000, 68306): 0.1875,\n",
              " (65684, 66537): 0.1875,\n",
              " (68007, 70560): 0.1875,\n",
              " (68306, 75542): 0.1875,\n",
              " (73218, 74751): 0.1875,\n",
              " (81942, 82992): 0.1875,\n",
              " (446, 24218): 0.18518518518518517,\n",
              " (1806, 13087): 0.18518518518518517,\n",
              " (1806, 62554): 0.18518518518518517,\n",
              " (1806, 79759): 0.18518518518518517,\n",
              " (4829, 9631): 0.18518518518518517,\n",
              " (4829, 75542): 0.18518518518518517,\n",
              " (6750, 9194): 0.18518518518518517,\n",
              " (6750, 31385): 0.18518518518518517,\n",
              " (6750, 53483): 0.18518518518518517,\n",
              " (6750, 70333): 0.18518518518518517,\n",
              " (6830, 38316): 0.18518518518518517,\n",
              " (7114, 8243): 0.18518518518518517,\n",
              " (7114, 57800): 0.18518518518518517,\n",
              " (7158, 24218): 0.18518518518518517,\n",
              " (7936, 14759): 0.18518518518518517,\n",
              " (7936, 25632): 0.18518518518518517,\n",
              " (7946, 62554): 0.18518518518518517,\n",
              " (8243, 14759): 0.18518518518518517,\n",
              " (8604, 41262): 0.18518518518518517,\n",
              " (8621, 13317): 0.18518518518518517,\n",
              " (8621, 18092): 0.18518518518518517,\n",
              " (8621, 25136): 0.18518518518518517,\n",
              " (8621, 66810): 0.18518518518518517,\n",
              " (8621, 70610): 0.18518518518518517,\n",
              " (8621, 80521): 0.18518518518518517,\n",
              " (9069, 25632): 0.18518518518518517,\n",
              " (9069, 44781): 0.18518518518518517,\n",
              " (9194, 13087): 0.18518518518518517,\n",
              " (9194, 82156): 0.18518518518518517,\n",
              " (9350, 25632): 0.18518518518518517,\n",
              " (9350, 44781): 0.18518518518518517,\n",
              " (10500, 54549): 0.18518518518518517,\n",
              " (10522, 14759): 0.18518518518518517,\n",
              " (10975, 18389): 0.18518518518518517,\n",
              " (11789, 14759): 0.18518518518518517,\n",
              " (12134, 43592): 0.18518518518518517,\n",
              " (12134, 49164): 0.18518518518518517,\n",
              " (12134, 72797): 0.18518518518518517,\n",
              " (13087, 37727): 0.18518518518518517,\n",
              " (13317, 49960): 0.18518518518518517,\n",
              " (14664, 18445): 0.18518518518518517,\n",
              " (14759, 27288): 0.18518518518518517,\n",
              " (14759, 34284): 0.18518518518518517,\n",
              " (14759, 44588): 0.18518518518518517,\n",
              " (14759, 74700): 0.18518518518518517,\n",
              " (15283, 46767): 0.18518518518518517,\n",
              " (18092, 21174): 0.18518518518518517,\n",
              " (18123, 20743): 0.18518518518518517,\n",
              " (18389, 52716): 0.18518518518518517,\n",
              " (18389, 75515): 0.18518518518518517,\n",
              " (18445, 27209): 0.18518518518518517,\n",
              " (18445, 59379): 0.18518518518518517,\n",
              " (19601, 25282): 0.18518518518518517,\n",
              " (20143, 29178): 0.18518518518518517,\n",
              " (20143, 46762): 0.18518518518518517,\n",
              " (20743, 66810): 0.18518518518518517,\n",
              " (20784, 27587): 0.18518518518518517,\n",
              " (20784, 57075): 0.18518518518518517,\n",
              " (20817, 77551): 0.18518518518518517,\n",
              " (21174, 34156): 0.18518518518518517,\n",
              " (21174, 57499): 0.18518518518518517,\n",
              " (21174, 66810): 0.18518518518518517,\n",
              " (21174, 69356): 0.18518518518518517,\n",
              " (21525, 27687): 0.18518518518518517,\n",
              " (22283, 55489): 0.18518518518518517,\n",
              " (22338, 82156): 0.18518518518518517,\n",
              " (22853, 57075): 0.18518518518518517,\n",
              " (23608, 79759): 0.18518518518518517,\n",
              " (23646, 69356): 0.18518518518518517,\n",
              " (23646, 75066): 0.18518518518518517,\n",
              " (23647, 41604): 0.18518518518518517,\n",
              " (23647, 77552): 0.18518518518518517,\n",
              " (24450, 62554): 0.18518518518518517,\n",
              " (25347, 44781): 0.18518518518518517,\n",
              " (25612, 41478): 0.18518518518518517,\n",
              " (25632, 32071): 0.18518518518518517,\n",
              " (25632, 74429): 0.18518518518518517,\n",
              " (25632, 74700): 0.18518518518518517,\n",
              " (25808, 50304): 0.18518518518518517,\n",
              " (27209, 78089): 0.18518518518518517,\n",
              " (27288, 27587): 0.18518518518518517,\n",
              " (27587, 31613): 0.18518518518518517,\n",
              " (27587, 57499): 0.18518518518518517,\n",
              " (27587, 66810): 0.18518518518518517,\n",
              " (28873, 73103): 0.18518518518518517,\n",
              " (29141, 36611): 0.18518518518518517,\n",
              " (30285, 59367): 0.18518518518518517,\n",
              " (31228, 70780): 0.18518518518518517,\n",
              " (31385, 62554): 0.18518518518518517,\n",
              " (31613, 63077): 0.18518518518518517,\n",
              " (33139, 71959): 0.18518518518518517,\n",
              " (34076, 78456): 0.18518518518518517,\n",
              " (34156, 57075): 0.18518518518518517,\n",
              " (36611, 57075): 0.18518518518518517,\n",
              " (36611, 81572): 0.18518518518518517,\n",
              " (39694, 44781): 0.18518518518518517,\n",
              " (41262, 44781): 0.18518518518518517,\n",
              " (41262, 51454): 0.18518518518518517,\n",
              " (41466, 49960): 0.18518518518518517,\n",
              " (44555, 71959): 0.18518518518518517,\n",
              " (44781, 53788): 0.18518518518518517,\n",
              " (44781, 74700): 0.18518518518518517,\n",
              " (44781, 81323): 0.18518518518518517,\n",
              " (47908, 57075): 0.18518518518518517,\n",
              " (48960, 62079): 0.18518518518518517,\n",
              " (49960, 57499): 0.18518518518518517,\n",
              " (49960, 66810): 0.18518518518518517,\n",
              " (50794, 59270): 0.18518518518518517,\n",
              " (53483, 56784): 0.18518518518518517,\n",
              " (54545, 66981): 0.18518518518518517,\n",
              " (55147, 61179): 0.18518518518518517,\n",
              " (55147, 62738): 0.18518518518518517,\n",
              " (55147, 71959): 0.18518518518518517,\n",
              " (55147, 78268): 0.18518518518518517,\n",
              " (57075, 75066): 0.18518518518518517,\n",
              " (57075, 80521): 0.18518518518518517,\n",
              " (57499, 63077): 0.18518518518518517,\n",
              " (57499, 78268): 0.18518518518518517,\n",
              " (57558, 62554): 0.18518518518518517,\n",
              " (59270, 76450): 0.18518518518518517,\n",
              " (60230, 76422): 0.18518518518518517,\n",
              " (61179, 75066): 0.18518518518518517,\n",
              " (62738, 80521): 0.18518518518518517,\n",
              " (67089, 78456): 0.18518518518518517,\n",
              " (67089, 79759): 0.18518518518518517,\n",
              " (71959, 75066): 0.18518518518518517,\n",
              " (204, 10975): 0.18181818181818182,\n",
              " (5544, 6639): 0.18181818181818182,\n",
              " (6602, 30815): 0.18181818181818182,\n",
              " (6602, 65862): 0.18181818181818182,\n",
              " (6760, 55293): 0.18181818181818182,\n",
              " (7247, 79602): 0.18181818181818182,\n",
              " (7443, 47723): 0.18181818181818182,\n",
              " (13127, 28290): 0.18181818181818182,\n",
              " (15001, 68306): 0.18181818181818182,\n",
              " (20790, 81895): 0.18181818181818182,\n",
              " (24233, 25490): 0.18181818181818182,\n",
              " (24233, 40724): 0.18181818181818182,\n",
              " (24233, 68229): 0.18181818181818182,\n",
              " (24601, 65862): 0.18181818181818182,\n",
              " (25271, 26546): 0.18181818181818182,\n",
              " (25271, 41207): 0.18181818181818182,\n",
              " (25490, 55293): 0.18181818181818182,\n",
              " (28287, 79602): 0.18181818181818182,\n",
              " (28290, 81072): 0.18181818181818182,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_50_items = dict(islice(sorted_dict.items(), 50)) # work with 50 sentences as a start"
      ],
      "metadata": {
        "id": "lpey9YHFeeAz"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_50_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPjRWEGAeeDa",
        "outputId": "a60c7e41-4ac7-4999-dcdc-968e3a1e1e88"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(23472, 23473): 0.8823529411764706,\n",
              " (33139, 76450): 0.4,\n",
              " (43561, 57499): 0.34615384615384615,\n",
              " (66810, 76450): 0.34615384615384615,\n",
              " (43561, 76450): 0.3333333333333333,\n",
              " (21174, 33789): 0.32,\n",
              " (49960, 76450): 0.32,\n",
              " (33050, 76450): 0.3103448275862069,\n",
              " (76450, 79602): 0.3103448275862069,\n",
              " (1806, 76450): 0.3076923076923077,\n",
              " (7936, 9069): 0.3076923076923077,\n",
              " (7936, 74700): 0.3076923076923077,\n",
              " (9069, 74700): 0.3076923076923077,\n",
              " (50794, 53483): 0.3076923076923077,\n",
              " (9069, 18389): 0.30434782608695654,\n",
              " (7936, 75122): 0.2962962962962963,\n",
              " (8621, 33050): 0.2962962962962963,\n",
              " (18123, 76450): 0.2962962962962963,\n",
              " (23383, 32071): 0.2962962962962963,\n",
              " (33050, 49960): 0.2962962962962963,\n",
              " (33139, 62478): 0.2962962962962963,\n",
              " (50794, 75066): 0.2962962962962963,\n",
              " (57499, 76450): 0.2962962962962963,\n",
              " (70446, 72226): 0.2962962962962963,\n",
              " (7247, 66810): 0.2857142857142857,\n",
              " (13317, 81072): 0.2857142857142857,\n",
              " (14069, 67509): 0.2857142857142857,\n",
              " (22101, 72226): 0.2857142857142857,\n",
              " (62478, 76450): 0.2857142857142857,\n",
              " (6818, 73103): 0.28,\n",
              " (9069, 14759): 0.28,\n",
              " (9069, 37353): 0.28,\n",
              " (44781, 57800): 0.28,\n",
              " (55147, 57075): 0.28,\n",
              " (57075, 69356): 0.28,\n",
              " (7247, 76450): 0.27586206896551724,\n",
              " (13127, 32539): 0.27586206896551724,\n",
              " (33050, 57499): 0.27586206896551724,\n",
              " (36483, 73997): 0.27586206896551724,\n",
              " (50794, 73218): 0.27586206896551724,\n",
              " (55147, 79602): 0.27586206896551724,\n",
              " (55293, 62478): 0.27586206896551724,\n",
              " (6750, 33139): 0.2692307692307692,\n",
              " (7936, 67089): 0.2692307692307692,\n",
              " (7936, 79759): 0.2692307692307692,\n",
              " (9069, 79759): 0.2692307692307692,\n",
              " (11713, 46767): 0.2692307692307692,\n",
              " (21137, 30285): 0.2692307692307692,\n",
              " (29417, 53483): 0.2692307692307692,\n",
              " (36611, 62554): 0.2692307692307692}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "\n",
        "values = list(first_50_items.values())\n",
        "mean_value = statistics.mean(values)\n",
        "mean_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EVnHdqXgv1l",
        "outputId": "69625fdc-5411-4ed5-9e79-860109bdb8b6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3054322343676255"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "\n",
        "values = list(first_50_items.values())\n",
        "mean_value = statistics.mean(values)\n",
        "mean_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8q3rIjLeeF3",
        "outputId": "3b93d470-76fe-4628-f44e-04ad356d9b63"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3054322343676255"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REPEAT PROCESS:\n"
      ],
      "metadata": {
        "id": "f6nU_ptamwxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = filtered_df['txt']\n",
        "y = filtered_df['sentiment']"
      ],
      "metadata": {
        "id": "CfF1dBfymyLX"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_short_sentences.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "3hEZQGf1l5w4",
        "outputId": "5c161609-caff-4bba-a07c-2b1fc449e74e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    txt  sentiment  \\\n",
              "100   textbook: book shipped quickly and was in exce...          1   \n",
              "204   haven't found better yet...: this is the only ...          1   \n",
              "332   god's zoo: wonderful video, very comical and l...          1   \n",
              "446   good value: i love curve and this is a large b...          1   \n",
              "669   janes all the worlds aircraft 1996-7: great to...          1   \n",
              "686   edge of danger: 1 star - only because that's t...          0   \n",
              "725   needs $$ upgrade: only has limited access to o...          0   \n",
              "1232  a disappointment: maeve's forte is character d...          0   \n",
              "1436  frida's more attractive soundtrack sister: utt...          0   \n",
              "1806  ninnia: this monitor is great. the service i g...          1   \n",
              "\n",
              "      num_of_words                                           anon_txt  \n",
              "100             16  textbook: book shipped quickly and was in exce...  \n",
              "204             20  haven't found better yet...: this is the only ...  \n",
              "332             20  god's zoo: wonderful video, very comical and l...  \n",
              "446             20  good value: i love curve and this is a large b...  \n",
              "669             18  janes all the worlds aircraft 1996-7: great to...  \n",
              "686             18  edge of danger: 1 star - only because that's t...  \n",
              "725             20  needs $$ upgrade: only has limited access to o...  \n",
              "1232            19  a disappointment: maeve's forte is character d...  \n",
              "1436            15  frida's more attractive soundtrack sister: utt...  \n",
              "1806            20  ninnia: this monitor is great. the service i g...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55944846-9d4b-4f84-b224-4073ba4acd89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>num_of_words</th>\n",
              "      <th>anon_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>textbook: book shipped quickly and was in exce...</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>textbook: book shipped quickly and was in exce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>haven't found better yet...: this is the only ...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>haven't found better yet...: this is the only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>god's zoo: wonderful video, very comical and l...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>god's zoo: wonderful video, very comical and l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>good value: i love curve and this is a large b...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>good value: i love curve and this is a large b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>janes all the worlds aircraft 1996-7: great to...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>janes all the worlds aircraft 1996-7: great to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>edge of danger: 1 star - only because that's t...</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>edge of danger: 1 star - only because that's t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>needs $$ upgrade: only has limited access to o...</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>needs $$ upgrade: only has limited access to o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>a disappointment: maeve's forte is character d...</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>a disappointment: maeve's forte is character d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>frida's more attractive soundtrack sister: utt...</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>frida's more attractive soundtrack sister: utt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>ninnia: this monitor is great. the service i g...</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>ninnia: this monitor is great. the service i g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55944846-9d4b-4f84-b224-4073ba4acd89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55944846-9d4b-4f84-b224-4073ba4acd89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55944846-9d4b-4f84-b224-4073ba4acd89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CHECK K ANONYMITY:"
      ],
      "metadata": {
        "id": "7IGUcR3Ej3A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer is defined only once\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
        "                           stop_words='english')\n",
        "\n",
        "def get_pesonal_docs(docs, min_k = 2):\n",
        "    \"\"\" If K not given, returns the minimal current k and the corresponding documents.\n",
        "        If k is given, return the documents with k or less neighbohrs  \"\"\"\n",
        "    \n",
        "    # Lemmatizing the documents\n",
        "    ldocs = lemmatize_docs(docs)\n",
        "\n",
        "    # Vectorizing\n",
        "    count_data = vectorizer.fit_transform(ldocs)\n",
        "    \n",
        "    # Counting unique values\n",
        "    uniq_arr, uniq_cnt = np.unique(count_data.toarray(), axis=0, return_counts=True)\n",
        "    if not min_k:\n",
        "        min_k = min(uniq_cnt)\n",
        "    \n",
        "    # All the unique vectors\n",
        "    un_anon = uniq_arr[uniq_cnt <= min_k]\n",
        "\n",
        "    # Getting the unique vectore indeces\n",
        "    indeces_arr = None\n",
        "    for row in un_anon:\n",
        "        similar_vals = np.where((count_data.toarray() == (row)).all(axis=1))\n",
        "        similar_vals_arr = np.expand_dims(similar_vals[0], axis=0)\n",
        "        if indeces_arr is None:  # First iteration\n",
        "            indeces_arr = similar_vals_arr\n",
        "        else:\n",
        "            indeces_arr = np.concatenate((indeces_arr, similar_vals_arr), axis=0)\n",
        "    \n",
        "    # Getting the unique indeces\n",
        "    indeces_arr = np.unique(indeces_arr, axis=0).astype(int)\n",
        "    #print(np.where(count_data.toarray() == un_anon[range(un_anon.shape[0]),:]))\n",
        "    return min_k, un_anon, indeces_arr"
      ],
      "metadata": {
        "id": "9LBhzs9VeeIE"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZjVTSldKkLSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df_short_sentences.anon_txt.iloc[0:10]\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrYWKS7dkg1N",
        "outputId": "7a41f948-36d9-4d87-f298-a0ecf06d5f01"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100     textbook: book shipped quickly and was in exce...\n",
              "204     haven't found better yet...: this is the only ...\n",
              "332     god's zoo: wonderful video, very comical and l...\n",
              "446     good value: i love curve and this is a large b...\n",
              "669     janes all the worlds aircraft 1996-7: great to...\n",
              "686     edge of danger: 1 star - only because that's t...\n",
              "725     needs $$ upgrade: only has limited access to o...\n",
              "1232    a disappointment: maeve's forte is character d...\n",
              "1436    frida's more attractive soundtrack sister: utt...\n",
              "1806    ninnia: this monitor is great. the service i g...\n",
              "Name: anon_txt, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_k, un_anon, indeces_arr = get_pesonal_docs(corpus)\n",
        "print(indeces_arr)\n",
        "for row in indeces_arr:\n",
        "    docs = []\n",
        "    for i in row:\n",
        "        docs.append(corpus[i])\n",
        "    print(docs)\n",
        "\n",
        "        \n",
        "#print([corpus[i] for i in indeces_arr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "hP4FIrCckLoe",
        "outputId": "ab792936-3f68-4625-d2b1-2ea54ec4f0d3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-5ea685393ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mun_anon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindeces_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pesonal_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindeces_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindeces_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-a5bb3e7a869e>\u001b[0m in \u001b[0;36mget_pesonal_docs\u001b[0;34m(docs, min_k)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Lemmatizing the documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mldocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatize_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Vectorizing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lemmatize_docs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) repeat  2-5\n"
      ],
      "metadata": {
        "id": "uvb4iagqj6AG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1B2TI08Fjyjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " PCA - ploting the clusters using"
      ],
      "metadata": {
        "id": "SZGxY52nu3KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the embeddings from the embedded_dict and store them in a numpy array\n",
        "embeddings = np.array(list(embedded_dict.values()))\n",
        "\n",
        "# Perform PCA on the embeddings to reduce their dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(embeddings)\n",
        "\n",
        "# Get the cluster labels assigned by DBSCAN\n",
        "labels = dbscan.labels_\n",
        "\n",
        "# Plot the 2D embeddings with different colors for each cluster\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-o6tBMA8uxFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-SNE - plotting the clusters"
      ],
      "metadata": {
        "id": "mHFcKBGAu6UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the embeddings from the embedded_dict and store them in a numpy array\n",
        "embeddings = np.array(list(embedded_dict.values()))\n",
        "\n",
        "# Perform t-SNE on the embeddings to reduce their dimensionality to 2\n",
        "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
        "embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "# Get the cluster labels assigned by DBSCAN\n",
        "labels = dbscan.labels_\n",
        "\n",
        "# Plot the 2D embeddings with different colors for each cluster\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-vpf6cu5u2nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Change all words in the Dict to \"Centroid\" or choose a new words of our own.\n",
        "replace it in the original text of the dataframe.\n"
      ],
      "metadata": {
        "id": "433O6DVIuBND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TBD"
      ],
      "metadata": {
        "id": "64J4qbUruPef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Check if we get k=2"
      ],
      "metadata": {
        "id": "B3tLtCv0uPu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1) Create BoW representation"
      ],
      "metadata": {
        "id": "sYGND8zYGnji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatizing"
      ],
      "metadata": {
        "id": "SIZVpptwHHKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial \n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Defining the document\n",
        "    doc = nlp(doc) \n",
        "\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    \n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    #if len(txt) > 2:\n",
        "    #    return ' '.join(txt)\n",
        "    return ' '.join(txt)"
      ],
      "metadata": {
        "id": "hiAl_U-7GxIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df_short_sentences['txt'])"
      ],
      "metadata": {
        "id": "pLT-WnCaG2Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_lemmas = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000)]"
      ],
      "metadata": {
        "id": "HtN8gGBzHJ08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing documents with None"
      ],
      "metadata": {
        "id": "tH6sd8iVMegF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_lemmas = [d for d in train_sentences_lemmas if d ]"
      ],
      "metadata": {
        "id": "CTkhjuHk3ss3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before and after cleaning:"
      ],
      "metadata": {
        "id": "nLk4BTW6HSkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before:\\t', df_short_sentences['txt'][6])\n",
        "print('After:\\t',train_sentences_lemmas[6])"
      ],
      "metadata": {
        "id": "vAA0fku_HRZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing"
      ],
      "metadata": {
        "id": "ZsIIqdPGGuVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
        "                           stop_words='english')\n",
        "\n",
        "count_data = vectorizer.fit_transform(train_sentences_lemmas)\n",
        "\n",
        "#create dataframe\n",
        "bow_dataframe = pd.DataFrame(count_data.toarray(),columns=vectorizer.get_feature_names_out())\n",
        "bow_dataframe"
      ],
      "metadata": {
        "id": "gQ-hsQWhuAlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find sentences with low anonymity"
      ],
      "metadata": {
        "id": "nbOYloQrNibn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniq_arr, uniq_cnt = np.unique(count_data.toarray(), axis=0, return_counts=True)"
      ],
      "metadata": {
        "id": "HTLNgGG_NoQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The current k value is', min(uniq_cnt))"
      ],
      "metadata": {
        "id": "8yUCY94WuAn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "arr = [[4, 4, 5], [4, 4, 5], [7, 7, 7]]\n",
        "np.unique(arr, axis=0, return_counts=True)"
      ],
      "metadata": {
        "id": "In4tr5L-O309"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2) Collecting the above code into one anonimity test function"
      ],
      "metadata": {
        "id": "PXqJG9A3QJ-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_docs(docs):\n",
        "    \"\"\" Lemmatizes documents using spacy \"\"\"\n",
        "    brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in docs)\n",
        "    clean_docs = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000)]\n",
        "    clean_docs = [d for d in clean_docs if d]\n",
        "    return clean_docs"
      ],
      "metadata": {
        "id": "YQ61ZewD3eYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer is defined only once\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1), # to use bigrams ngram_range=(2,2)\n",
        "                           stop_words='english')\n",
        "\n",
        "def get_pesonal_docs(docs, min_k = None):\n",
        "    \"\"\" If K not given, returns the minimal current k and the corresponding documents.\n",
        "        If k is given, return the documents with k or less neighbohrs  \"\"\"\n",
        "    \n",
        "    # Lemmatizing the documents\n",
        "    ldocs = lemmatize_docs(docs)\n",
        "\n",
        "    # Vectorizing\n",
        "    count_data = vectorizer.fit_transform(ldocs)\n",
        "    \n",
        "    # Counting unique values\n",
        "    uniq_arr, uniq_cnt = np.unique(count_data.toarray(), axis=0, return_counts=True)\n",
        "    if not min_k:\n",
        "        min_k = min(uniq_cnt)\n",
        "    \n",
        "    # All the unique vectors\n",
        "    un_anon = uniq_arr[uniq_cnt <= min_k]\n",
        "\n",
        "    # Getting the unique vectore indeces\n",
        "    indeces_arr = None\n",
        "    for row in un_anon:\n",
        "        similar_vals = np.where((count_data.toarray() == (row)).all(axis=1))\n",
        "        similar_vals_arr = np.expand_dims(similar_vals[0], axis=0)\n",
        "        if indeces_arr is None:  # First iteration\n",
        "            indeces_arr = similar_vals_arr\n",
        "        else:\n",
        "            indeces_arr = np.concatenate((indeces_arr, similar_vals_arr), axis=0)\n",
        "    \n",
        "    # Getting the unique indeces\n",
        "    indeces_arr = np.unique(indeces_arr, axis=0).astype(int)\n",
        "    #print(np.where(count_data.toarray() == un_anon[range(un_anon.shape[0]),:]))\n",
        "    return min_k, un_anon, indeces_arr\n"
      ],
      "metadata": {
        "id": "QEtERZ3OPr-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['I love banana', 'banana I love', 'orange big', 'big orange', 'big orange']\n",
        "min_k, un_anon, indeces_arr = get_pesonal_docs(corpus)\n",
        "print(indeces_arr)\n",
        "for row in indeces_arr:\n",
        "    docs = []\n",
        "    for i in row:\n",
        "        docs.append(corpus[i])\n",
        "    print(docs)\n",
        "\n",
        "        \n",
        "#print([corpus[i] for i in indeces_arr])"
      ],
      "metadata": {
        "id": "PFWznvajSjPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Finding neighboring words"
      ],
      "metadata": {
        "id": "xOfFv75CiZ2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function to find the neihboring words from the same cluster"
      ],
      "metadata": {
        "id": "kuGQKgbchc3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_neighbors_words(cluster_dic, word):\n",
        "    \"\"\" Gets the other words in the cluster\"\"\"\n",
        "    ret_list = []\n",
        "    for key, vals in cluster_dic.items():\n",
        "        if word in vals:\n",
        "            ret_list += vals\n",
        "    return ret_list"
      ],
      "metadata": {
        "id": "Y3zkY9PTctFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defininig a function that gets a words, find the neighboring words and returns the general word using word embedding"
      ],
      "metadata": {
        "id": "_3FKB7xMxBSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_general_word(cluster_dic, we_model, word):\n",
        "    \"\"\" Find the nearest words by clusters and \n",
        "    returns the most similar words usind word embedding\"\"\"\n",
        "    neighbors_words = get_neighbors_words(cluster_dic, word)\n",
        "    if neighbors_words:\n",
        "        we_word = we_model.most_similar(neighbors_words, topn=1)[0][0]\n",
        "    else:\n",
        "        we_word = None\n",
        "    return we_word"
      ],
      "metadata": {
        "id": "m6l8qLAbf6-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "cg_eg_T-xQ9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_general_word(clusters, glove_model, 'four')"
      ],
      "metadata": {
        "id": "PypkcyrXdXcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_general_word(clusters, glove_model, 'red')"
      ],
      "metadata": {
        "id": "dQ0yqnn9mC7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_general_word(clusters, glove_model, 'hello')"
      ],
      "metadata": {
        "id": "dXJU4dF3mMrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8) Changing unique words"
      ],
      "metadata": {
        "id": "3BkfBqP8xVdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the protected words"
      ],
      "metadata": {
        "id": "pdDprmOFxpFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "protected_words = sw + []"
      ],
      "metadata": {
        "id": "-iIp4V77S97p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to ignore protected words in the unique documents count, we will create an alternative document list, in which we will remove the proected words from the word list"
      ],
      "metadata": {
        "id": "Ma4PsUdoyqwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_from_docs(docs, prot_word_list):\n",
        "    \"\"\" Removes words from documen \"\"\"\n",
        "    new_docs = []\n",
        "    for d in docs:\n",
        "        one_doc = ''\n",
        "        for w in d.split(' '):\n",
        "            if w not in prot_word_list:\n",
        "                one_doc = f'{one_doc} {w}'\n",
        "        new_docs.append(one_doc)\n",
        "    return new_docs\n",
        "\n",
        "#train_sentences_lemmas\n",
        "remove_from_docs(['is not great', 'hi hi is', 'orange'], protected_words)"
      ],
      "metadata": {
        "id": "Jxk2fSUqzM8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_short_no_prot = remove_from_docs(df_short_sentences['txt'], protected_words)\n",
        "min_k, un_anon, indeces_arr = get_pesonal_docs(df_short_no_prot)"
      ],
      "metadata": {
        "id": "w6ZCCC1S3MPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_k"
      ],
      "metadata": {
        "id": "MF1K-Cckn932"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "un_anon"
      ],
      "metadata": {
        "id": "B-_SKy5uwzfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indeces_arr"
      ],
      "metadata": {
        "id": "GClerHlzPmoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in indeces_arr:\n",
        "    docs = []\n",
        "    for i in row:\n",
        "        docs.append(df_short_no_prot[i])\n",
        "    print(docs)"
      ],
      "metadata": {
        "id": "9HCYO8dPuAq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_wB4_NfuAtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDaFFsVRuAwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltxwchGkgZZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UGnADJM3gZcY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}